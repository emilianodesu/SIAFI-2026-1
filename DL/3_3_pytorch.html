<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>pytorch – SIAFI Data Science and Machine Learning Handbook 2026-1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-299fde5381b5a602aab895950093955a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">SIAFI Data Science and Machine Learning Handbook 2026-1</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-introduction-to-data-science" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Introduction to Data Science</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-introduction-to-data-science">    
        <li>
    <a class="dropdown-item" href="../IDS/1_1_fundamentals.html">
 <span class="dropdown-text">Fundamentals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../IDS/1_3_end_to_end_ml_project.html">
 <span class="dropdown-text">End to End Machine Learning Project</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../IDS/1_4_dimensionality_reduction.html">
 <span class="dropdown-text">Dimensionality Reduction</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-machine-learning" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Machine Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-machine-learning">    
        <li>
    <a class="dropdown-item" href="../ML/2_1_intro.html">
 <span class="dropdown-text">Introduction to Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/2_2_slf.html">
 <span class="dropdown-text">Supervised Learning Fundamentals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/2_3_classification.html">
 <span class="dropdown-text">Classification Fundamentals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/2_3_2_classification_algorithms.html">
 <span class="dropdown-text">Classification Algorithms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/2_4_regression.html">
 <span class="dropdown-text">Regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/2_5_decision_trees.html">
 <span class="dropdown-text">Decision Trees and Random Forests</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/2_6_unsupervised_learning.html">
 <span class="dropdown-text">Unsupervised Learning</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-deep-learning" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Deep Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-deep-learning">    
        <li>
    <a class="dropdown-item" href="../DL/3_1_fundamentals.html">
 <span class="dropdown-text">Fundamentals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../DL/3_2_ann.html">
 <span class="dropdown-text">Artificial Neurons and the Perceptron</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../DL/3_3_pytorch.html">
 <span class="dropdown-text">Building Neural Networks with PyTorch</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#deep-learning" id="toc-deep-learning" class="nav-link active" data-scroll-target="#deep-learning">3. Deep Learning</a>
  <ul class="collapse">
  <li><a href="#pytorch-fundamentals" id="toc-pytorch-fundamentals" class="nav-link" data-scroll-target="#pytorch-fundamentals">3.3 PyTorch Fundamentals</a>
  <ul class="collapse">
  <li><a href="#pytorch-tensors" id="toc-pytorch-tensors" class="nav-link" data-scroll-target="#pytorch-tensors">3.3.1 PyTorch Tensors</a></li>
  <li><a href="#hardware-acceleration" id="toc-hardware-acceleration" class="nav-link" data-scroll-target="#hardware-acceleration">3.3.2 Hardware Acceleration</a></li>
  <li><a href="#autograd" id="toc-autograd" class="nav-link" data-scroll-target="#autograd">3.3.3 Autograd</a></li>
  <li><a href="#linear-regression-with-pytorch" id="toc-linear-regression-with-pytorch" class="nav-link" data-scroll-target="#linear-regression-with-pytorch">3.3.4 Linear Regression with PyTorch</a></li>
  <li><a href="#regression-mlp" id="toc-regression-mlp" class="nav-link" data-scroll-target="#regression-mlp">3.3.5 Regression MLP</a></li>
  <li><a href="#minibatch-gradient-descent-with-dataloader" id="toc-minibatch-gradient-descent-with-dataloader" class="nav-link" data-scroll-target="#minibatch-gradient-descent-with-dataloader">3.3.6 Minibatch Gradient Descent with DataLoader</a></li>
  <li><a href="#model-evaluation" id="toc-model-evaluation" class="nav-link" data-scroll-target="#model-evaluation">3.3.7 Model Evaluation</a></li>
  <li><a href="#building-nonsequential-custom-modules" id="toc-building-nonsequential-custom-modules" class="nav-link" data-scroll-target="#building-nonsequential-custom-modules">3.3.8 Building Nonsequential Custom Modules</a></li>
  <li><a href="#building-an-image-classifier-with-pytorch" id="toc-building-an-image-classifier-with-pytorch" class="nav-link" data-scroll-target="#building-an-image-classifier-with-pytorch">3.3.9 Building an Image Classifier with PyTorch</a></li>
  <li><a href="#fine-tuning-with-optuna" id="toc-fine-tuning-with-optuna" class="nav-link" data-scroll-target="#fine-tuning-with-optuna">3.3.10 Fine-Tuning with Optuna</a></li>
  <li><a href="#saving-and-loading-pytorch-models" id="toc-saving-and-loading-pytorch-models" class="nav-link" data-scroll-target="#saving-and-loading-pytorch-models">3.3.11 Saving and Loading PyTorch Models</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<p><a href="https://colab.research.google.com/github/emilianodesu/SIAFI-2026-1/blob/main/DL/3_3_pytorch.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<div id="a09012dc" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'font'</span>, size<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'axes'</span>, labelsize<span class="op">=</span><span class="dv">14</span>, titlesize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'legend'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'xtick'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'ytick'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Are we using Colab?</p>
<div id="1b4897b0" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>IS_COLAB <span class="op">=</span> <span class="st">"google.colab"</span> <span class="kw">in</span> sys.modules</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If using Colab, a couple libraries are not pre-installed so we must install them manually:</p>
<div id="c2e4aca7" class="cell" data-outputid="836a6b29-5f53-4682-c7b0-65329f054765" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> IS_COLAB:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">%</span>pip install <span class="op">-</span>q optuna torchmetrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/404.7 kB ? eta -:--:--   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 399.4/404.7 kB 15.8 MB/s eta 0:00:01   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 404.7/404.7 kB 10.1 MB/s eta 0:00:00
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/983.2 kB ? eta -:--:--   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 983.0/983.2 kB 96.9 MB/s eta 0:00:01   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 983.2/983.2 kB 17.7 MB/s eta 0:00:00</code></pre>
</div>
</div>
<p>And of course we need PyTorch, specifically PyTorch ≥ 2.6.0:</p>
<div id="af4c722b" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> packaging.version <span class="im">import</span> Version</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> Version(torch.__version__) <span class="op">&gt;=</span> Version(<span class="st">"2.6.0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="deep-learning" class="level1">
<h1>3. Deep Learning</h1>
<section id="pytorch-fundamentals" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-fundamentals">3.3 PyTorch Fundamentals</h2>
<p>The core data structure of PyTorch is the <em>tensor</em>.⁠ It’s a multidimensional array with a shape and a data type, used for numerical computations. Isn’t that exactly like a NumPy array? Well, yes, it is! But a tensor also has two extra features: it can live on a GPU (or other hardware accelerators, as we will see), and it supports auto-differentiation. Every neural network we will build from now on will input and output tensors (much like Scikit-Learn models input and output NumPy arrays). So let’s start by looking at how to create and manipulate tensors.</p>
<section id="pytorch-tensors" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-tensors">3.3.1 PyTorch Tensors</h3>
<p>You can create a PyTorch tensor much like you would create a NumPy array. For example, let’s create a 2 × 3 array:</p>
<div id="2734d606" class="cell" data-outputid="dcc98bac-e470-49f6-ef76-3839d3d75c22" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>, <span class="fl">4.0</span>, <span class="fl">7.0</span>], [<span class="fl">2.0</span>, <span class="fl">3.0</span>, <span class="fl">6.0</span>]])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([[1., 4., 7.],
        [2., 3., 6.]])</code></pre>
</div>
</div>
<p>Just like a NumPy array, a tensor can contain floats, integers, booleans, or complex numbers—just one data type per tensor. If you initialize a tensor with values of different types, then the most general one will be selected (i.e., complex &gt; float &gt; integer &gt; bool). You can also select the data type explicitly when creating the tensor, for example <code>dtype=torch.float16</code> for 16-bit floats. Note that tensors of strings or objects are not supported.</p>
<p>You can get a tensor’s shape and data type like this:</p>
<div id="9df3dc60" class="cell" data-outputid="bf20e713-b1c4-4b8c-ca3c-9ab1e07bff03" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X.shape, X.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>(torch.Size([2, 3]), torch.float32)</code></pre>
</div>
</div>
<p>Indexing works just like for NumPy arrays:</p>
<div id="6263d1da" class="cell" data-outputid="60fe3cf3-2304-4b8f-f802-52d71fa87de0" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X[<span class="dv">0</span>, <span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor(4.)</code></pre>
</div>
</div>
<div id="6b9305f8" class="cell" data-outputid="ec360f3f-1741-4384-a63a-e4322185e633" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X[:, <span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([4., 3.])</code></pre>
</div>
</div>
<p>You can also run all sorts of computations on tensors, and the API is conveniently similar to NumPy’s: for example, there’s <code>torch.abs()</code>, <code>torch.cos()</code>, <code>torch.exp()</code>, <code>torch.max()</code>, <code>torch.mean()</code>, <code>torch.sqrt()</code>, and so on. PyTorch tensors also have methods for most of these operations, so you can write <code>X.exp()</code> instead of <code>torch.exp(X)</code>. Let’s try a few operations:</p>
<div id="a9291a7b" class="cell" data-outputid="9d66fb5f-bffe-477b-cf27-789446c75cd5" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="op">*</span> (X <span class="op">+</span> <span class="fl">1.0</span>)  <span class="co"># item-wise addition and multiplication</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>tensor([[20., 50., 80.],
        [30., 40., 70.]])</code></pre>
</div>
</div>
<div id="5fb075c8" class="cell" data-outputid="df9c0708-ac00-42bd-b1e4-58715a6c10b3" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X.exp()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([[   2.7183,   54.5981, 1096.6332],
        [   7.3891,   20.0855,  403.4288]])</code></pre>
</div>
</div>
<div id="18e68675" class="cell" data-outputid="a454421c-96a1-4434-c665-00180afb307d" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>X.mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor(3.8333)</code></pre>
</div>
</div>
<div id="cbbf1298" class="cell" data-outputid="5f7591d0-e0df-461e-a17b-cd64c4d6eee0" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>X.<span class="bu">max</span>(dim<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>torch.return_types.max(
values=tensor([2., 4., 7.]),
indices=tensor([1, 0, 0]))</code></pre>
</div>
</div>
<div id="7e1b6242" class="cell" data-outputid="fa469c4b-7b2c-4c7c-a8f6-66ef14926d60" data-execution_count="13">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">@</span> X.T  <span class="co"># matrix transpose and matrix multiplication</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([[66., 56.],
        [56., 49.]])</code></pre>
</div>
</div>
<p>You can also convert a tensor to a NumPy array using the <code>numpy()</code> method, and create a tensor from a NumPy array:</p>
<div id="92e39626" class="cell" data-outputid="871f160e-cd3b-46a2-ad18-77ee976fde8e" data-execution_count="14">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>X.numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>array([[1., 4., 7.],
       [2., 3., 6.]], dtype=float32)</code></pre>
</div>
</div>
<div id="dea8b5d2" class="cell" data-outputid="41d773dc-6f13-4b24-b606-c70c2f2c3636" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>torch.tensor(np.array([[<span class="fl">1.</span>, <span class="fl">4.</span>, <span class="fl">7.</span>], [<span class="fl">2.</span>, <span class="fl">3.</span>, <span class="fl">6.</span>]]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[1., 4., 7.],
        [2., 3., 6.]], dtype=torch.float64)</code></pre>
</div>
</div>
<p>Notice that the default precision for floats is 32 bits in PyTorch, whereas it’s 64 bits in NumPy. It’s generally better to use 32 bits in deep learning because this takes half the RAM and speeds up computations, and neural nets do not actually need the extra precision offered by 64-bit floats. So when calling the <code>torch.tensor()</code> function to convert a NumPy array to a tensor, it’s best to specify <code>dtype=torch.float32</code>. Alternatively, you can use <code>torch.FloatTensor()</code> which automatically converts the array to 32 bits:</p>
<div id="e88e5cce" class="cell" data-outputid="ec5239c9-96d3-42a4-917f-72f6461efc49" data-execution_count="16">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>torch.tensor(np.array([[<span class="fl">1.</span>, <span class="fl">4.</span>, <span class="fl">7.</span>], [<span class="fl">2.</span>, <span class="fl">3.</span>, <span class="fl">6.</span>]]), dtype<span class="op">=</span>torch.float32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([[1., 4., 7.],
        [2., 3., 6.]])</code></pre>
</div>
</div>
<div id="627f539a" class="cell" data-outputid="de92779a-b354-4c9e-c755-528f999fab4c" data-execution_count="17">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>torch.FloatTensor(np.array([[<span class="fl">1.</span>, <span class="fl">4.</span>, <span class="fl">7.</span>], [<span class="fl">2.</span>, <span class="fl">3.</span>, <span class="dv">6</span>]]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([[1., 4., 7.],
        [2., 3., 6.]])</code></pre>
</div>
</div>
<p><strong>Tip</strong>: Both <code>torch.tensor()</code> and <code>torch.FloatTensor()</code> make a copy of the given NumPy array. If you prefer, you can use <code>torch.​from_numpy()</code> which creates a tensor on the CPU that just uses the NumPy array’s data directly, without copying it. But beware: modifying the NumPy array will also modify the tensor, and vice versa.</p>
<p>You can also modify a tensor in place using indexing and slicing, as with a NumPy array:</p>
<div id="c0626bc9" class="cell" data-outputid="e9e372ad-039c-4245-913e-9f522df7cea2" data-execution_count="18">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>X[:, <span class="dv">1</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">99</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([[  1., -99.,   7.],
        [  2., -99.,   6.]])</code></pre>
</div>
</div>
<p>PyTorch’s API provides many in-place operations, such as <code>abs_()</code>, <code>sqrt_()</code>, and <code>zero_()</code>, which modify the input tensor directly: they can sometimes save some memory and speed up your models. For example, the <code>relu_()</code> method applies the ReLU activation function in place by replacing all negative values with 0s:</p>
<div id="79545f84" class="cell" data-outputid="bee06068-e0db-4b4b-e138-5f3d1d95828d" data-execution_count="19">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>X.relu_()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([[1., 0., 7.],
        [2., 0., 6.]])</code></pre>
</div>
</div>
<p><strong>Tip</strong>: PyTorch’s in-place operations are easy to spot at a glance because their name always ends with an underscore. With very few exceptions (e.g., <code>zero_()</code>), removing the underscore gives you the regular operation (e.g., <code>abs_()</code> is in place, <code>abs()</code> is not).</p>
</section>
<section id="hardware-acceleration" class="level3">
<h3 class="anchored" data-anchor-id="hardware-acceleration">3.3.2 Hardware Acceleration</h3>
<p>PyTorch tensors can be copied easily to the GPU, assuming your machine has a compatible GPU, and you have the required libraries installed. On Colab, all you need to do is ensure that you are using a GPU runtime: for this, go to the Runtime menu and select “Change runtime type”, then make sure a GPU is selected (e.g., an Nvidia T4 GPU). The GPU runtime will automatically have the appropriate PyTorch library installed—compiled with GPU support—as well as the appropriate GPU drivers and related libraries (e.g., Nvidia’s CUDA and cuDNN libraries).⁠ If you prefer to run the code on your own machine, you will need to ensure that you have all the drivers and libraries required.</p>
<p>Let’s check whether PyTorch can access an Nvidia GPU or Apple’s MPS, otherwise let’s fall back to the CPU:</p>
<div id="87deb4d7" class="cell" data-outputid="2173d9e1-8cc3-441d-943e-1d30ddfd09be" data-execution_count="20">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"cuda"</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.backends.mps.is_available():</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"mps"</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"cpu"</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>'cuda'</code></pre>
</div>
</div>
<p>On a Colab GPU runtime, device will be equal to <code>"cuda"</code>. Now let’s create a tensor on that GPU. To do that, one option is to create the tensor on the CPU, then copy it to the GPU using the <code>to()</code> method:</p>
<div id="d7ceff11" class="cell" data-outputid="a5c5b717-8604-43f1-9c34-cc10a1a254a3" data-execution_count="21">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> torch.tensor([[<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">3.</span>], [<span class="fl">4.</span>, <span class="fl">5.</span>, <span class="fl">6.</span>]])</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> M.to(device)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>M.device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>device(type='cuda', index=0)</code></pre>
</div>
</div>
<p><strong>Tip</strong>: The <code>cpu()</code> and <code>cuda()</code> methods are short for <code>to("cpu")</code> and <code>to("cuda")</code>, respectively.</p>
<p>Alternatively, we can create the tensor directly on the GPU using the <code>device</code> argument:</p>
<div id="c4d289ac" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> torch.tensor([[<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">3.</span>], [<span class="fl">4.</span>, <span class="fl">5.</span>, <span class="fl">6.</span>]], device<span class="op">=</span>device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Tip</strong>: If you have multiple Nvidia GPUs, you can refer to the desired GPU by appending the GPU index: <code>"cuda:0"</code> (or just <code>"cuda"</code>) for GPU #0, <code>"cuda:1"</code> for GPU #1, and so on.</p>
<p>Once the tensor is on the GPU, we can run operations on it normally, and they will all take place on the GPU:</p>
<div id="41b929f0" class="cell" data-outputid="ae2a8722-6040-482f-bf91-b1745dfcda70" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> M <span class="op">@</span> M.T  <span class="co"># run some operations on the GPU</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>R</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([[14., 32.],
        [32., 77.]], device='cuda:0')</code></pre>
</div>
</div>
<p>Note that the result <code>R</code> also lives on the GPU. This means we can perform multiple operations on the GPU without having to transfer data back and forth between the CPU and the GPU. This is crucial in deep learning because data transfer between devices can often become a performance bottleneck.</p>
<p>How much does a GPU accelerate the computations? Let’s run a little test to compare the speed of a matrix multiplication running on the CPU versus the GPU:⁠</p>
<div id="f4e7d25c" class="cell" data-outputid="97bdb8ec-2059-4923-c7a3-2c1a017c3bc4" data-execution_count="24">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> torch.rand((<span class="dv">1000</span>, <span class="dv">1000</span>))  <span class="co"># on the CPU</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>M <span class="op">@</span> M.T  <span class="co"># warmup</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit M <span class="op">@</span> M.T</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> M.to(device)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>M <span class="op">@</span> M.T  <span class="co"># warmup</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit M <span class="op">@</span> M.T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>49.8 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
548 µs ± 16.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)</code></pre>
</div>
</div>
<p>All right, now that we’ve seen what tensors are and how to use them on the CPU or the GPU, let’s look at PyTorch’s auto-differentiation feature.</p>
</section>
<section id="autograd" class="level3">
<h3 class="anchored" data-anchor-id="autograd">3.3.3 Autograd</h3>
<p>PyTorch comes with an efficient implementation of reverse-mode auto-differentiation, called <em>autograd</em>, which stands for automatic gradients. It is quite easy to use. For example, consider a simple function, <span class="math inline">\(f(x) = x^2\)</span>. Differential calculus tells us that the derivative of this function is <span class="math inline">\(f’(x) = 2x\)</span>. If we evaluate <span class="math inline">\(f(5)\)</span> and <span class="math inline">\(f'(5)\)</span>, we get 25 and 10, respectively. Let’s see if PyTorch agrees:</p>
<div id="aa6611b7" class="cell" data-outputid="9b5565c0-6564-495b-e308-6feb19c60a37" data-execution_count="25">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">5.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>f</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor(25., grad_fn=&lt;PowBackward0&gt;)</code></pre>
</div>
</div>
<div id="716342e0" class="cell" data-outputid="ae3922f7-232c-4267-aa20-4c866ab98f40" data-execution_count="26">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>f.backward()</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor(10.)</code></pre>
</div>
</div>
<p>Great, we got the correct results: <code>f</code> is 25, and <code>x.grad</code> is 10! Note that the <code>backward()</code> function automatically computed the gradient <span class="math inline">\(f'(x)\)</span> at the same point <span class="math inline">\(x = 5.0\)</span>. Let’s go through this code line by line:</p>
<ul>
<li>First, we created a tensor <code>x</code>, equal to 5.0, and we told PyTorch that it’s a variable (not a constant) by specifying <code>requires_grad=True</code>. Knowing this, PyTorch will automatically keep track of all operations involving <code>x</code>: this is needed because PyTorch must capture the computation graph in order to run backprop on it and obtain the derivative of <code>f</code> with regard to <code>x</code>. In this computation graph, the tensor <code>x</code> is a <em>leaf node</em>.</li>
<li>Then we compute <code>f = x ** 2</code>. The result is a tensor equal to 25.0, the square of 5.0. But wait, there’s more to it: <code>f</code> also carries a <code>grad_fn</code> attribute which represents the operation that created this tensor (<code>**</code>, power, hence the name <code>PowBackward0</code>), and which tells PyTorch how to backpropagate the gradients through this particular operation. This <code>grad_fn</code> attribute is how PyTorch keeps track of the computation graph.</li>
<li>Next, we call <code>f.backward()</code>: this backpropagates the gradients through the computation graph, starting with <code>f</code>, and all the way back to the leaf nodes (just <code>x</code> in this case).</li>
<li>Lastly, we can just read the <code>x</code> tensor’s <code>grad</code> attribute, which was computed during backprop: this gives us the derivative of <code>f</code> with regard to <code>x</code>. Ta-da!</li>
</ul>
<p>PyTorch creates a new computation graph on the fly during each forward pass, as the operations are executed. This allows PyTorch to support very dynamic models containing loops and conditionals.</p>
<p>After computing the gradients, you generally want to perform a gradient descent step by subtracting a fraction of the gradients from the model variables (at least when training a neural network). In our simple example, running gradient descent will gradually push <code>x</code> toward 0, since that’s the value that minimizes <span class="math inline">\(f(x) = x^2\)</span>. To do a gradient descent step, you must temporarily disable gradient tracking since you don’t want to track the gradient descent step itself in the computation graph (in fact, PyTorch would raise an exception if you tried to run an in-place operation on a tracked variable). This can be done by placing the gradient descent step inside a <code>torch.no_grad()</code> context, like this:</p>
<div id="96d66ac7" class="cell" data-outputid="57c18c58-fd59-4a18-c154-b26a431e69e9" data-execution_count="27">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-=</span> learning_rate <span class="op">*</span> x.grad  <span class="co"># gradient descent step</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor(4., requires_grad=True)</code></pre>
</div>
</div>
<p>The variable <code>x</code> gets decremented by 0.1 * 10.0 = 1.0, down from 5.0 to 4.0.</p>
<p>Another way to avoid gradient computation is to use the variable’s <code>detach()</code> method: this creates a new tensor detached from the computation graph, with <code>requires_grad=False</code>, but still pointing to the same data in memory. You can then update this detached tensor:</p>
<p>Since <code>x_detached</code> and <code>x</code> share the same memory, modifying <code>x_detached</code> also modifies <code>x</code>.</p>
<div id="32b6452f" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>x_detached <span class="op">=</span> x.detach()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>x_detached <span class="op">-=</span> learning_rate <span class="op">*</span> x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>detach()</code> method can be handy when you need to run some computation on a tensor without affecting the gradients (e.g., for evaluation or logging), or when you need fine-grained control over which operations should contribute to gradient computation. Using <code>no_grad()</code> is generally preferred when performing inference or doing a gradient descent step, as it provides a convenient context-wide method to disable gradient tracking.</p>
<p>Lastly, before you repeat the whole process (forward pass + backward pass + gradient descent step), it’s essential to zero out the gradients of every model parameter (you don’t need a <code>no_grad()</code> context for this since the gradient tensor has <code>requires_grad=False</code>):</p>
<div id="21b28d93" class="cell" data-outputid="94ec74aa-44a2-4eec-c624-bdc94f536f25" data-execution_count="29">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>x.grad.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor(0.)</code></pre>
</div>
</div>
<p><strong>Warning</strong>: If you forget to zero out the gradients at each training iteration, the <code>backward()</code> method will just accumulate them, causing incorrect gradient descent updates. Since there won’t be any explicit error, just low performance (and perhaps infinite or NaN values), this issue may be hard to debug.</p>
<p>Putting everything together, the whole training loop looks like this:</p>
<div id="e9ef00eb" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">5.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span>  <span class="co"># forward pass</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    f.backward()  <span class="co"># backward pass</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-=</span> learning_rate <span class="op">*</span> x.grad  <span class="co"># gradient descent step</span></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    x.grad.zero_()  <span class="co"># reset the gradients</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="df5b8961" class="cell" data-outputid="94a740f8-ba75-4e27-e795-a885be05b47d" data-execution_count="31">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor(1.0185e-09, requires_grad=True)</code></pre>
</div>
</div>
<p><strong>Tip</strong>: Implement your models first without any in-place operations, then if you need to save some memory or speed up your model a bit, you can try converting some of the most costly operations to their in-place counterparts. Just make sure that your model still outputs the same result for a given input, and also make sure you don’t modify in place a tensor needed for backprop (you will get a <code>RuntimeError</code> in this case).</p>
</section>
<section id="linear-regression-with-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression-with-pytorch">3.3.4 Linear Regression with PyTorch</h3>
<section id="implementing-linear-regression-from-scratch" class="level4">
<h4 class="anchored" data-anchor-id="implementing-linear-regression-from-scratch">3.3.4.1 Implementing Linear Regression from Scratch</h4>
<p>We will start by implementing linear regression using tensors and autograd directly, then we will simplify the code using PyTorch’s high-level API, and also add GPU support.</p>
<p>Let’s tackle the California housing dataset:</p>
<div id="2d956c4d" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>housing <span class="op">=</span> fetch_california_housing()</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>X_train_full, X_test, y_train_full, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    housing.data, housing.target, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>X_train, X_valid, y_train, y_valid <span class="op">=</span> train_test_split(</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    X_train_full, y_train_full, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, let’s convert it to tensors and normalize it. We could use a StandardScaler for this, but let’s just use tensor operations instead, to get a bit of practice:</p>
<div id="e553bc83" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> torch.FloatTensor(X_train)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>X_valid <span class="op">=</span> torch.FloatTensor(X_valid)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> torch.FloatTensor(X_test)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> X_train.mean(dim<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>stds <span class="op">=</span> X_train.std(dim<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> (X_train <span class="op">-</span> means) <span class="op">/</span> stds</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>X_valid <span class="op">=</span> (X_valid <span class="op">-</span> means) <span class="op">/</span> stds</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> (X_test <span class="op">-</span> means) <span class="op">/</span> stds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>PyTorch expects the targets to have one row per sample, so let’s reshape the targets to be column vectors:</p>
<div id="317f1122" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> torch.FloatTensor(y_train).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>y_valid <span class="op">=</span> torch.FloatTensor(y_valid).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> torch.FloatTensor(y_test).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that the data is ready, let’s create the parameters of our linear regression model:</p>
<div id="eb5a3a4f" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> X_train.shape[<span class="dv">1</span>]  <span class="co"># there are 8 input features</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn((n_features, <span class="dv">1</span>), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="fl">0.</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now have a weights parameter <code>w</code> (a column vector with one weight per input dimension, in this case 8), and a bias parameter <code>b</code> (a single scalar). The weights are initialized randomly, while the bias is initialized to zero. We could have initialized the weights to zero as well in this case, but when we get to neural networks it will be important to initialize the weights randomly to break the symmetry between neurons, so we might as well get into the habit now.</p>
<p>Next, let’s train our model. For now we will use batch gradient descent (BGD), using the full training set at each training step:</p>
<div id="34dac5bc" class="cell" data-outputid="ddbfa8ac-25a1-4ffb-d142-00e9efbf6f60" data-execution_count="36">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> X_train <span class="op">@</span> w <span class="op">+</span> b</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> ((y_pred <span class="op">-</span> y_train) <span class="op">**</span> <span class="dv">2</span>).mean()</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>        b <span class="op">-=</span> learning_rate <span class="op">*</span> b.grad</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> learning_rate <span class="op">*</span> w.grad</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>        b.grad.zero_()</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>        w.grad.zero_()</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, Loss: 16.158456802368164
Epoch 2/20, Loss: 4.8793745040893555
Epoch 3/20, Loss: 2.255225419998169
Epoch 4/20, Loss: 1.3307634592056274
Epoch 5/20, Loss: 0.9680691957473755
Epoch 6/20, Loss: 0.8142675757408142
Epoch 7/20, Loss: 0.7417045831680298
Epoch 8/20, Loss: 0.7020701169967651
Epoch 9/20, Loss: 0.6765918731689453
Epoch 10/20, Loss: 0.6577965021133423
Epoch 11/20, Loss: 0.6426151990890503
Epoch 12/20, Loss: 0.6297222971916199
Epoch 13/20, Loss: 0.6184942126274109
Epoch 14/20, Loss: 0.6085968613624573
Epoch 15/20, Loss: 0.5998216867446899
Epoch 16/20, Loss: 0.592018723487854
Epoch 17/20, Loss: 0.5850691795349121
Epoch 18/20, Loss: 0.578873336315155
Epoch 19/20, Loss: 0.573345422744751
Epoch 20/20, Loss: 0.5684100389480591</code></pre>
</div>
</div>
<p>Let’s walk through this code:</p>
<ul>
<li>First we define the <code>learning_rate</code> hyperparameter. You can experiment with different values to find a value that converges fast and gives a precise result.</li>
<li>Next, we run 20 epochs. We could implement early stopping to find the right moment to stop and avoid overfitting, but we will keep things simple for now.</li>
<li>Next, we run the forward pass: we compute the predictions <code>y_pred</code>, and the mean squared error loss.</li>
<li>Then we run <code>loss.backward()</code> to compute the gradients of the loss with regard to every model parameter. This is autograd in action.</li>
<li>Next, we use the gradients <code>b.grad</code> and <code>w.grad</code> to perform a gradient descent step. Notice that we’re running this code inside a <code>with torch.no_grad()</code> context, as discussed earlier.</li>
<li>Once we’ve done the gradient descent step, we reset the gradients to zero (very important!).</li>
<li>Lastly, we print the epoch number and the current loss at each epoch. The <code>item()</code> method extracts the value of a scalar tensor.</li>
</ul>
<p>Congratulations, you just trained your first model using PyTorch! You can now use the model to make predictions for some new data <code>X_new</code> (which must be represented as a PyTorch tensor). For example, let’s make predictions for the first three instances in the test set:</p>
<div id="3ac67690" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> X_test[:<span class="dv">3</span>]  <span class="co"># pretend these are new instances</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> X_new <span class="op">@</span> w <span class="op">+</span> b  <span class="co"># use the trained parameters to make predictions</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="941c0cd3" class="cell" data-outputid="1f73ddbf-71c0-4c4a-d2c1-a2d503105b95" data-execution_count="38">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([[0.8916],
        [1.6480],
        [2.6577]])</code></pre>
</div>
</div>
<p><strong>Tip</strong>: It’s best to use a <code>with torch.no_grad()</code> context during inference: PyTorch will consume less RAM and run faster since it won’t have to keep track of the computation graph.</p>
</section>
<section id="linear-regression-using-pytorchs-high-level-api" class="level4">
<h4 class="anchored" data-anchor-id="linear-regression-using-pytorchs-high-level-api">3.3.4.2 Linear Regression Using PyTorch’s High-Level API</h4>
<p>PyTorch provides an implementation of linear regression in the <code>torch.nn.Linear</code> class, so let’s use it:</p>
<div id="a7eed427" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn  <span class="co"># by convention, this module is usually imported this way</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)  <span class="co"># to get reproducible results</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Linear(in_features<span class="op">=</span>n_features, out_features<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>nn.Linear</code> class (short for <code>torch.nn.Linear</code>) is one of many modules provided by PyTorch. Each module is a subclass of the <code>nn.Module</code> class. To build a simple linear regression model, a single <code>nn.Linear</code> module is all you need. However, for most neural networks you will need to assemble many modules, as we will see later in this chapter, so you can think of modules as math LEGO® bricks. Many modules contain model parameters. For example, the <code>nn.Linear</code> module contains a bias vector (with one bias term per neuron), and a weight matrix (with one row per neuron and one column per input dimension, which is the transpose of the weight matrix). Since our model has a single neuron (because <code>out_features=1</code>), the bias vector contains a single bias term, and the weight matrix contains a single row. These parameters are accessible directly as attributes of the <code>nn.Linear</code> module:</p>
<div id="f791083f" class="cell" data-outputid="26a87e1f-769e-484e-e314-7f43d4c8ea8a" data-execution_count="40">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>model.bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>Parameter containing:
tensor([0.3117], requires_grad=True)</code></pre>
</div>
</div>
<div id="7f14666d" class="cell" data-outputid="8fc0e307-96dc-4705-eb9b-be7740c1d144" data-execution_count="41">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>model.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Parameter containing:
tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],
       requires_grad=True)</code></pre>
</div>
</div>
<p>Notice that both parameters were automatically initialized randomly (which is why we used <code>manual_seed()</code> to get reproducible results). These parameters are instances of the <code>torch.nn.Parameter</code> class, which is a subclass of the <code>torch.Tensor</code> class: this means that you can use them exactly like normal tensors. A module’s <code>parameters()</code> method returns an iterator over all of the module’s attributes of type <code>Parameter</code>, as well as all the parameters of all its submodules, recursively (if it has any). It does not return regular tensors, even those with <code>requires_grad=True</code>. That’s the main difference between a regular tensor and a <code>Parameter</code>:</p>
<div id="0ac71a36" class="cell" data-outputid="7ddd0dd6-7837-449d-f172-3768fe3f4ab4" data-execution_count="42">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(param) <span class="co"># Do something with each parameter</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameter containing:
tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],
       requires_grad=True)
Parameter containing:
tensor([0.3117], requires_grad=True)</code></pre>
</div>
</div>
<p>A module can be called just like a regular function. For example, let’s make some predictions for the first two instances in the training set (since the model is not trained yet, its parameters are random and the predictions are terrible):</p>
<div id="23e795fa" class="cell" data-outputid="94ad7339-bdf6-4516-aa35-dd5ccfaa735a" data-execution_count="43">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>model(X_train[:<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([[-0.4718],
        [ 0.1131]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<p>When we use a module as a function, PyTorch internally calls the module’s <code>forward()</code> method. In the case of the <code>nn.Linear</code> module, the <code>forward()</code> method computes <code>X @ self.weight.T + self.bias</code> (where <code>X</code> is the input). That’s just what we need for linear regression!</p>
<p>Notice that the result contains the <code>grad_fn</code> attribute, showing that autograd did its job and tracked the computation graph while the model was making its predictions.</p>
<p>Now that we have our model, we need to create an optimizer to update the model parameters, and we must also choose a loss function:</p>
<div id="cb030fd5" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>PyTorch provides a few different optimizers. Here we’re using the simple stochastic gradient descent (SGD) optimizer, which can be used for SGD, mini-batch GD, or batch gradient descent. To initialize it, we must give it the model parameters and the learning rate.</p>
<p>For the loss function, we create an instance of the <code>nn.MSELoss</code> class: this is also a module, so we can use it like a function, giving it the predictions and the targets, and it will compute the MSE. The <code>nn</code> module contains many other loss functions and other neural net tools, as we will see. Next, let’s write a small function to train our model:</p>
<div id="bf4c030a" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_train)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_train)</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compare this training loop with our earlier training loop: it’s very similar, but we’re now using higher-level constructs rather than working directly with tensors and autograd. Here are a few things to note:</p>
<ul>
<li>In PyTorch, the loss function object is commonly referred to as the <em>criterion</em>, to distinguish it from the loss value itself (which is computed at each training iteration using the criterion). In this example, it’s the <code>MSELoss</code> instance.</li>
<li>The <code>optimizer.step()</code> line corresponds to the two lines that updated <code>b</code> and <code>w</code> in our earlier code.</li>
<li>And of course the <code>optimizer.zero_grad()</code> line corresponds to the two lines that zeroed out <code>b.grad</code> and <code>w.grad</code>. Notice that we don’t need to use with torch.no_grad() here since this is done automatically by the optimizer, inside the step() and zero_grad() functions.</li>
</ul>
<p>Now let’s call this function to train our model!</p>
<div id="8d969f2b" class="cell" data-outputid="76013d1e-6e7d-4e5e-a97c-51819aae053a" data-execution_count="46">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, Loss: 4.3378496170043945
Epoch 2/20, Loss: 0.7802939414978027
Epoch 3/20, Loss: 0.6253842115402222
Epoch 4/20, Loss: 0.6060433983802795
Epoch 5/20, Loss: 0.5956299304962158
Epoch 6/20, Loss: 0.587356686592102
Epoch 7/20, Loss: 0.5802990794181824
Epoch 8/20, Loss: 0.5741382837295532
Epoch 9/20, Loss: 0.5687101483345032
Epoch 10/20, Loss: 0.5639079809188843
Epoch 11/20, Loss: 0.5596511363983154
Epoch 12/20, Loss: 0.5558737516403198
Epoch 13/20, Loss: 0.5525194406509399
Epoch 14/20, Loss: 0.5495392084121704
Epoch 15/20, Loss: 0.5468900203704834
Epoch 16/20, Loss: 0.544533908367157
Epoch 17/20, Loss: 0.5424376726150513
Epoch 18/20, Loss: 0.5405716300010681
Epoch 19/20, Loss: 0.5389097332954407
Epoch 20/20, Loss: 0.5374288558959961</code></pre>
</div>
</div>
<p>All good; the model is trained, and you can now use it to make predictions by simply calling it like a function (preferably inside a <code>no_grad()</code> context, as we saw earlier):</p>
<div id="71ccfaad" class="cell" data-outputid="76bf4d58-dbec-4b8f-b6bf-98e54d4bc955" data-execution_count="47">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> X_test[:<span class="dv">3</span>]  <span class="co"># pretend these are new instances</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model(X_new)  <span class="co"># use the trained model to make predictions</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([[0.8061],
        [1.7116],
        [2.6973]])</code></pre>
</div>
</div>
<p>Now that you are familiar with PyTorch’s high-level API, you are ready to go beyond linear regression and build a multilayer perceptron.</p>
</section>
</section>
<section id="regression-mlp" class="level3">
<h3 class="anchored" data-anchor-id="regression-mlp">3.3.5 Regression MLP</h3>
<p>PyTorch provides a helpful <code>nn.Sequential</code> module that chains multiple modules: when you call this module with some inputs, it feeds these inputs to the first module, then feeds the output of the first module to the second module, and so on. Most neural networks contain stacks of modules, and in fact many neural networks are just one big stack of modules: this makes the <code>nn.Sequential</code> module one of the most useful modules in PyTorch. The MLP we want to build is just that: a simple stack of modules—two hidden layers and one output layer. So let’s build it using the <code>nn.Sequential</code> module:</p>
<div id="c7ffd7e9" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    nn.Linear(n_features, <span class="dv">50</span>),</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>),</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">40</span>, <span class="dv">1</span>)</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s go through each layer:</p>
<ul>
<li>The first layer must have the right number of inputs for our data: <code>n_features</code> (equal to 8 in our case). However, it can have any number of outputs: let’s pick 50 (that’s a hyperparameter we can tune).</li>
<li>Next we have an <code>nn.ReLU</code> module, which implements the ReLU activation function for the first hidden layer. This module does not contain any model parameters, and it acts itemwise so the shape of its output is equal to the shape of its input.</li>
<li>The second hidden layer must have the same number of inputs as the output of the previous layer: in this case, 50. However, it can have any number of outputs. It’s common to use the same number of output dimensions in all hidden layers, but in this example we used 40 to make it clear that the output of one layer must match the input of the next layer.</li>
<li>Then again, an <code>nn.ReLU</code> module to implement the second hidden layer’s activation function.</li>
<li>Finally, the output layer must have 40 inputs, but this time its number of outputs is not free: it must match the targets’ dimensionality. Since our targets have a single dimension, we must have just one output dimension in the output layer.</li>
</ul>
<p>Now let’s train the model just like we did before:</p>
<div id="f9bbf690" class="cell" data-outputid="f4304803-3f69-40a7-d72b-48d134ffbb88" data-execution_count="49">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, Loss: 5.045480251312256
Epoch 2/20, Loss: 2.0523123741149902
Epoch 3/20, Loss: 1.0039883852005005
Epoch 4/20, Loss: 0.8570139408111572
Epoch 5/20, Loss: 0.7740675210952759
Epoch 6/20, Loss: 0.7225847244262695
Epoch 7/20, Loss: 0.6893726587295532
Epoch 8/20, Loss: 0.6669032573699951
Epoch 9/20, Loss: 0.6507738828659058
Epoch 10/20, Loss: 0.6383934020996094
Epoch 11/20, Loss: 0.6281993389129639
Epoch 12/20, Loss: 0.6193399429321289
Epoch 13/20, Loss: 0.6113173365592957
Epoch 14/20, Loss: 0.6038705706596375
Epoch 15/20, Loss: 0.5968307852745056
Epoch 16/20, Loss: 0.5901119112968445
Epoch 17/20, Loss: 0.5836468935012817
Epoch 18/20, Loss: 0.5774063467979431
Epoch 19/20, Loss: 0.5713554620742798
Epoch 20/20, Loss: 0.565444827079773</code></pre>
</div>
</div>
<p>That’s it, you can tell your friends you trained your first neural network with PyTorch! However, we are still using batch gradient descent, computing the gradients over the entire training set at each iteration. This works with small datasets, but if we want to be able to scale up to large datasets and large models, we need to switch to mini-batch gradient descent.</p>
</section>
<section id="minibatch-gradient-descent-with-dataloader" class="level3">
<h3 class="anchored" data-anchor-id="minibatch-gradient-descent-with-dataloader">3.3.6 Minibatch Gradient Descent with DataLoader</h3>
<p>To help implement mini-batch GD, PyTorch provides a class named <code>DataLoader</code> in the <code>torch.utils.data</code> module. It can efficiently load batches of data of the desired size, and shuffle the data at each epoch if we want it to. The <code>DataLoader</code> expects the dataset to be represented as an object with at least two methods: <code>__len__(self)</code> to get the number of samples in the dataset, and <code>__getitem__(self, index)</code> to load the sample at the given index (including the target).</p>
<p>In our case, the training set is available in the <code>X_train</code> and <code>y_train</code> tensors, so we first need to wrap these tensors in a dataset object with the required API. To help with this, PyTorch provides a <code>TensorDataset</code> class. So let’s build a <code>TensorDataset</code> to wrap our training set, and a <code>DataLoader</code> to pull batches from this dataset. During training, we want the dataset to be shuffled, so we specify <code>shuffle=True</code>:</p>
<div id="42161abd" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset, DataLoader</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> TensorDataset(X_train, y_train)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have a larger model and we have the tools to train it one batch at a time, it’s a good time to start using hardware acceleration. It’s really quite simple: we just need to move the model to the GPU, which will move all of its parameters to the GPU RAM, and then at the start of each iteration during training we must copy each batch to the GPU. To move the model, we can just use its <code>to()</code> method, just like we did with tensors.</p>
<p>We can also create the loss function and optimizer, as earlier (but using a lower learning rate, such as 0.02).</p>
<div id="47618dc5" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    nn.Linear(n_features, <span class="dv">50</span>), nn.ReLU(),</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>), nn.ReLU(),</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">40</span>, <span class="dv">1</span>)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device)</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Warning</strong>: The optimizer will usually allocate its state on the same device as the model parameters, so it’s important to create the optimizer <em>after</em> you have moved the model to the GPU.</p>
<p>Now let’s create a <code>train()</code> function to implement mini-batch GD:</p>
<div id="ee0a79b6" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, optimizer, criterion, train_loader, n_epochs):</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>            X_batch, y_batch <span class="op">=</span> X_batch.to(device), y_batch.to(device)</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>        mean_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>mean_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>At every epoch, the function iterates through the whole training set, one batch at a time, and processes each batch just like earlier. But what about the very first line: <code>model.train()</code>? Well, this switches the model and all of its submodules to <em>training mode</em>. For now, this makes no difference at all, but it will be important in when we start using layers that behave differently during training and evaluation (e.g., <code>nn.Dropout</code> or <code>nn.BatchNorm1d</code>). Whenever you want to use the model outside of training (e.g., for evaluation, or to make predictions on new instances), you must first switch the model to <em>evaluation mode</em> by running <code>model.eval()</code>. Note that model.training holds a boolean that indicates the current mode.</p>
<p><strong>Tip</strong>: PyTorch itself does not provide a training loop implementation; you have to build it yourself. As we just saw, it’s not that long, and many people enjoy the freedom, clarity, and control this provides. However, if you would prefer to use a well-tested, off-the-shelf training loop with all the bells and whistles you need (such as multi-GPU support), then you can use a library such as PyTorch Lightning, FastAI, Catalyst, or Keras. These libraries are built on top of PyTorch and include a training loop and many other features (Keras supports PyTorch since version 3, and also supports TensorFlow and JAX). Check them out!</p>
<p>Now let’s call this train() function to train our model on the GPU:</p>
<div id="a1b9dd4d" class="cell" data-outputid="344670b1-5d7e-410c-ce69-12fc2f9f572b" data-execution_count="53">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>train(model, optimizer, mse, train_loader, n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, Loss: 0.5900
Epoch 2/20, Loss: 0.4046
Epoch 3/20, Loss: 0.3801
Epoch 4/20, Loss: 0.3629
Epoch 5/20, Loss: 0.3529
Epoch 6/20, Loss: 0.3520
Epoch 7/20, Loss: 0.3408
Epoch 8/20, Loss: 0.3427
Epoch 9/20, Loss: 0.3406
Epoch 10/20, Loss: 0.3378
Epoch 11/20, Loss: 0.3304
Epoch 12/20, Loss: 0.3267
Epoch 13/20, Loss: 0.3244
Epoch 14/20, Loss: 0.3221
Epoch 15/20, Loss: 0.3186
Epoch 16/20, Loss: 0.3149
Epoch 17/20, Loss: 0.3123
Epoch 18/20, Loss: 0.3111
Epoch 19/20, Loss: 0.3088
Epoch 20/20, Loss: 0.3072</code></pre>
</div>
</div>
<p>OK, time to step back a bit: you know the PyTorch fundamentals (tensors and autograd), you can build neural nets using PyTorch’s high-level API, and train them using mini-batch gradient descent, with the help of an optimizer, a criterion, and a data loader. The next step is to learn how to evaluate your model.</p>
</section>
<section id="model-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation">3.3.7 Model Evaluation</h3>
<p>Let’s write a function to evaluate the model. It takes the model and a <code>DataLoader</code> for the dataset that we want to evaluate the model on, as well as a function to compute the metric for a given batch, and lastly a function to aggregate the batch metrics (by default, it just computes the mean):</p>
<div id="d8932c6d" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate(model, data_loader, metric_fn, aggregate_fn<span class="op">=</span>torch.mean):</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    metrics <span class="op">=</span> []</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> data_loader:</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>            X_batch, y_batch <span class="op">=</span> X_batch.to(device), y_batch.to(device)</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>            metric <span class="op">=</span> metric_fn(y_pred, y_batch)</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>            metrics.append(metric)</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> aggregate_fn(torch.stack(metrics))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s build a <code>TensorDataset</code> and a <code>DataLoader</code> for our validation set, and pass it to our <code>evaluate()</code> function to compute the validation MSE:</p>
<div id="37f56628" class="cell" data-outputid="f8010b3b-deae-4036-fd0e-d2f24ad730d2" data-execution_count="55">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>valid_dataset <span class="op">=</span> TensorDataset(X_valid, y_valid)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>valid_loader <span class="op">=</span> DataLoader(valid_dataset, batch_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>valid_mse <span class="op">=</span> evaluate(model, valid_loader, mse)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>valid_mse</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor(0.4080, device='cuda:0')</code></pre>
</div>
</div>
<p>It works fine. But now suppose we want to use the RMSE instead of the MSE. PyTorch does not have a built-in function for that, but it’s easy enough to write:</p>
<div id="5b57e2b4" class="cell" data-outputid="9dc96bca-6cf1-4631-ee45-69ccd3f79972" data-execution_count="56">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rmse(y_pred, y_true):</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ((y_pred <span class="op">-</span> y_true) <span class="op">**</span> <span class="dv">2</span>).mean().sqrt()</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>evaluate(model, valid_loader, rmse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor(0.5668, device='cuda:0')</code></pre>
</div>
</div>
<p>But wait a second! The RMSE should be equal to the square root of the MSE; however, when we compute the square root of the MSE that we found earlier, we get a different result:</p>
<div id="3d0221c0" class="cell" data-outputid="3f521031-715e-4507-a0a1-747488279d85" data-execution_count="57">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>valid_mse.sqrt()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>tensor(0.6388, device='cuda:0')</code></pre>
</div>
</div>
<p>The reason is that instead of calculating the RMSE over the whole validation set, we computed it over each batch and then computed the mean of all these batch RMSEs. That’s not mathematically equivalent to computing the RMSE over the whole validation set. To solve this, we can use the MSE as our <code>metric_fn</code>, and use the <code>aggregate_fn</code> to compute the square root of the mean MSE:</p>
<div id="16c1d362" class="cell" data-outputid="f3085817-11aa-401d-ae6c-2d9bbdc39cc1" data-execution_count="58">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>evaluate(model, valid_loader, mse,</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>         aggregate_fn<span class="op">=</span><span class="kw">lambda</span> metrics: torch.sqrt(torch.mean(metrics)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>tensor(0.6388, device='cuda:0')</code></pre>
</div>
</div>
<p>That’s much better!</p>
<p>Rather than implement metrics yourself, you may prefer to use the TorchMetrics library (made by the same team as PyTorch Lightning), which provides many well-tested <em>streaming metrics</em>. A streaming metric is an object that keeps track of a given metric, and can be updated one batch at a time. The TorchMetrics library is not preinstalled on Colab, so we have to run</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install torchmetrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>then we can implement the <code>evaluate_tm()</code> function, like this:</p>
<div id="621d4947" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchmetrics</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_tm(model, data_loader, metric):</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>    metric.reset()  <span class="co"># reset the metric at the beginning</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> data_loader:</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>            X_batch, y_batch <span class="op">=</span> X_batch.to(device), y_batch.to(device)</span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)  <span class="co"># update it at each iteration</span></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metric.compute()  <span class="co"># compute the final result at the end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we can create an RMSE streaming metric, move it to the GPU, and use it to evaluate the validation set:</p>
<div id="f28f2375" class="cell" data-outputid="5f075c5c-afd4-488c-ac58-7f765fe5d319" data-execution_count="60">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>evaluate_tm(model, valid_loader, rmse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>tensor(0.6388, device='cuda:0')</code></pre>
</div>
</div>
<p>Sure enough, we get the correct result! Now try updating the <code>train()</code> function to evaluate your model’s performance during training, both on the training set (during each epoch) and on the validation set (at the end of each epoch). As always, if the performance on the training set is much better than on the validation set, your model is probably overfitting the training set, or there is a bug, such as a data mismatch between the training set and the validation set. This is easier to detect if you plot and analyze the learning curves. For this you can use Matplotlib, or a visualization tool such as TensorBoard.</p>
<div id="e8a8ae9f" class="cell" data-outputid="2077ad84-d750-4776-ae43-a037ba26eed3" data-execution_count="61">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train2(model, optimizer, criterion, metric, train_loader, valid_loader,</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>               n_epochs):</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">"train_losses"</span>: [], <span class="st">"train_metrics"</span>: [], <span class="st">"valid_metrics"</span>: []}</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>        metric.reset()</span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a>            model.train()</span>
<span id="cb102-9"><a href="#cb102-9" aria-hidden="true" tabindex="-1"></a>            X_batch, y_batch <span class="op">=</span> X_batch.to(device), y_batch.to(device)</span>
<span id="cb102-10"><a href="#cb102-10" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb102-11"><a href="#cb102-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb102-12"><a href="#cb102-12" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb102-13"><a href="#cb102-13" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb102-14"><a href="#cb102-14" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb102-15"><a href="#cb102-15" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb102-16"><a href="#cb102-16" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)</span>
<span id="cb102-17"><a href="#cb102-17" aria-hidden="true" tabindex="-1"></a>        mean_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb102-18"><a href="#cb102-18" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_losses"</span>].append(mean_loss)</span>
<span id="cb102-19"><a href="#cb102-19" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_metrics"</span>].append(metric.compute().item())</span>
<span id="cb102-20"><a href="#cb102-20" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"valid_metrics"</span>].append(</span>
<span id="cb102-21"><a href="#cb102-21" aria-hidden="true" tabindex="-1"></a>            evaluate_tm(model, valid_loader, metric).item())</span>
<span id="cb102-22"><a href="#cb102-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, "</span></span>
<span id="cb102-23"><a href="#cb102-23" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train loss: </span><span class="sc">{</span>history[<span class="st">'train_losses'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb102-24"><a href="#cb102-24" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train metric: </span><span class="sc">{</span>history[<span class="st">'train_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb102-25"><a href="#cb102-25" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"valid metric: </span><span class="sc">{</span>history[<span class="st">'valid_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb102-26"><a href="#cb102-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb102-27"><a href="#cb102-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-28"><a href="#cb102-28" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb102-29"><a href="#cb102-29" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb102-30"><a href="#cb102-30" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb102-31"><a href="#cb102-31" aria-hidden="true" tabindex="-1"></a>    nn.Linear(n_features, <span class="dv">50</span>), nn.ReLU(),</span>
<span id="cb102-32"><a href="#cb102-32" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>), nn.ReLU(),</span>
<span id="cb102-33"><a href="#cb102-33" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">40</span>, <span class="dv">30</span>), nn.ReLU(),</span>
<span id="cb102-34"><a href="#cb102-34" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">30</span>, <span class="dv">1</span>)</span>
<span id="cb102-35"><a href="#cb102-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb102-36"><a href="#cb102-36" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device)</span>
<span id="cb102-37"><a href="#cb102-37" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb102-38"><a href="#cb102-38" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb102-39"><a href="#cb102-39" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb102-40"><a href="#cb102-40" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train2(model, optimizer, mse, rmse, train_loader, valid_loader,</span>
<span id="cb102-41"><a href="#cb102-41" aria-hidden="true" tabindex="-1"></a>                 n_epochs)</span>
<span id="cb102-42"><a href="#cb102-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-43"><a href="#cb102-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Since we compute the training metric</span></span>
<span id="cb102-44"><a href="#cb102-44" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(n_epochs) <span class="op">+</span> <span class="fl">0.5</span>, history[<span class="st">"train_metrics"</span>], <span class="st">".--"</span>,</span>
<span id="cb102-45"><a href="#cb102-45" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb102-46"><a href="#cb102-46" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(n_epochs) <span class="op">+</span> <span class="fl">1.0</span>, history[<span class="st">"valid_metrics"</span>], <span class="st">".-"</span>,</span>
<span id="cb102-47"><a href="#cb102-47" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb102-48"><a href="#cb102-48" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb102-49"><a href="#cb102-49" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"RMSE"</span>)</span>
<span id="cb102-50"><a href="#cb102-50" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb102-51"><a href="#cb102-51" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Learning curves"</span>)</span>
<span id="cb102-52"><a href="#cb102-52" aria-hidden="true" tabindex="-1"></a>plt.axis((<span class="fl">0.5</span>, <span class="dv">20</span>, <span class="fl">0.4</span>, <span class="fl">1.0</span>))</span>
<span id="cb102-53"><a href="#cb102-53" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb102-54"><a href="#cb102-54" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 0.7826, train metric: 0.8847, valid metric: 0.6690
Epoch 2/20, train loss: 0.4362, train metric: 0.6605, valid metric: 0.6099
Epoch 3/20, train loss: 0.3930, train metric: 0.6269, valid metric: 0.6145
Epoch 4/20, train loss: 0.3759, train metric: 0.6132, valid metric: 0.5963
Epoch 5/20, train loss: 0.3649, train metric: 0.6040, valid metric: 0.5911
Epoch 6/20, train loss: 0.3598, train metric: 0.5999, valid metric: 0.5965
Epoch 7/20, train loss: 0.3530, train metric: 0.5941, valid metric: 0.6061
Epoch 8/20, train loss: 0.3495, train metric: 0.5911, valid metric: 0.6043
Epoch 9/20, train loss: 0.3455, train metric: 0.5877, valid metric: 0.5723
Epoch 10/20, train loss: 0.3416, train metric: 0.5846, valid metric: 0.6043
Epoch 11/20, train loss: 0.3401, train metric: 0.5831, valid metric: 0.5882
Epoch 12/20, train loss: 0.3362, train metric: 0.5799, valid metric: 0.5738
Epoch 13/20, train loss: 0.3352, train metric: 0.5788, valid metric: 0.5873
Epoch 14/20, train loss: 0.3310, train metric: 0.5754, valid metric: 0.5884
Epoch 15/20, train loss: 0.3291, train metric: 0.5736, valid metric: 0.5608
Epoch 16/20, train loss: 0.3272, train metric: 0.5721, valid metric: 0.5747
Epoch 17/20, train loss: 0.3264, train metric: 0.5714, valid metric: 0.5839
Epoch 18/20, train loss: 0.3238, train metric: 0.5691, valid metric: 0.5661
Epoch 19/20, train loss: 0.3207, train metric: 0.5663, valid metric: 0.5556
Epoch 20/20, train loss: 0.3190, train metric: 0.5649, valid metric: 0.5617</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3_3_pytorch_files/figure-html/cell-62-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now you know how to build, train, and evaluate a regression MLP using PyTorch, and how to use the trained model to make predictions. Great! But so far we have only looked at simple sequential models, composed of a sequence of linear layers and ReLU activation functions. How would you build a more complex, nonsequential model? For this, we will need to build custom modules.</p>
</section>
<section id="building-nonsequential-custom-modules" class="level3">
<h3 class="anchored" data-anchor-id="building-nonsequential-custom-modules">3.3.8 Building Nonsequential Custom Modules</h3>
<section id="wide-and-deep-network" class="level4">
<h4 class="anchored" data-anchor-id="wide-and-deep-network">3.3.8.1 Wide and Deep Network</h4>
<p>One example of a nonsequential neural network is a Wide &amp; Deep neural network. It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). The short path can also be used to provide manually engineered features to the neural network. In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/emilianodesu/SIAFI-2026-1/blob/main/DL/img/wad.png?raw=1" class="img-fluid figure-img"></p>
<figcaption>Wide and Deep Neural Network</figcaption>
</figure>
</div>
<p>Let’s build such a neural network to tackle the California housing dataset. Because this wide and deep architecture is nonsequential, we have to create a custom module. It’s easier than it sounds: just create a class derived from <code>torch.nn.Module</code>, then create all the layers you need in the constructor (after calling the base class’s <code>__init__()</code> method), and define how these layers should be used by the module in the <code>forward()</code> method:</p>
<div id="ba1b4286" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WideAndDeep(nn.Module):</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_features):</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.deep_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_features, <span class="dv">50</span>), nn.ReLU(),</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>), nn.ReLU(),</span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(<span class="dv">40</span> <span class="op">+</span> n_features, <span class="dv">1</span>)</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a>        deep_output <span class="op">=</span> <span class="va">self</span>.deep_stack(X)</span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a>        wide_and_deep <span class="op">=</span> torch.concat([X, deep_output], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.output_layer(wide_and_deep)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice that we can use any kind of module inside our custom module: in this example, we use an <code>nn.Sequential</code> module to build the “deep” part of our model (it’s actually not that deep; this is just a toy example). It’s the same MLP as earlier, except we separated the output layer because we need to feed it the concatenation of the model’s inputs and the deep part’s outputs. For this same reason, the output layer now has 40 + <code>n_features</code> inputs instead of just 40.</p>
<p>In the <code>forward()</code> method, we just feed the input X to the deep stack, concatenate the input and the deep stack’s output, and feed the result to the output layer.</p>
<p>Now we can create an instance of our custom module, move it to the GPU, train it, evaluate it, and use it exactly like our previous models:</p>
<div id="d6451e94" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WideAndDeep(n_features).to(device)</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.002</span>  <span class="co"># the model changed, so did the optimal learning rate</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="dabca3ab" class="cell" data-outputid="0258e160-99ef-4bfb-be8c-7c7181ba67d9" data-execution_count="64">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extra code: train the model, exactly our previous models</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train2(model, optimizer, mse, rmse, train_loader, valid_loader,</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>                 n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 1.4093, train metric: 1.1873, valid metric: 0.8794
Epoch 2/20, train loss: 0.6105, train metric: 0.7815, valid metric: 0.8410
Epoch 3/20, train loss: 0.5624, train metric: 0.7500, valid metric: 0.7263
Epoch 4/20, train loss: 0.5267, train metric: 0.7256, valid metric: 0.7730
Epoch 5/20, train loss: 0.5050, train metric: 0.7105, valid metric: 0.7300
Epoch 6/20, train loss: 0.4800, train metric: 0.6929, valid metric: 0.6787
Epoch 7/20, train loss: 0.4648, train metric: 0.6819, valid metric: 0.6950
Epoch 8/20, train loss: 0.4505, train metric: 0.6711, valid metric: 0.6437
Epoch 9/20, train loss: 0.4397, train metric: 0.6631, valid metric: 0.7005
Epoch 10/20, train loss: 0.4309, train metric: 0.6564, valid metric: 0.6289
Epoch 11/20, train loss: 0.4227, train metric: 0.6502, valid metric: 0.6604
Epoch 12/20, train loss: 0.4161, train metric: 0.6451, valid metric: 0.6223
Epoch 13/20, train loss: 0.4097, train metric: 0.6402, valid metric: 0.6729
Epoch 14/20, train loss: 0.4049, train metric: 0.6363, valid metric: 0.6330
Epoch 15/20, train loss: 0.3996, train metric: 0.6321, valid metric: 0.6719
Epoch 16/20, train loss: 0.3956, train metric: 0.6290, valid metric: 0.6473
Epoch 17/20, train loss: 0.3914, train metric: 0.6257, valid metric: 0.6379
Epoch 18/20, train loss: 0.3886, train metric: 0.6233, valid metric: 0.6175
Epoch 19/20, train loss: 0.3833, train metric: 0.6191, valid metric: 0.6195
Epoch 20/20, train loss: 0.3802, train metric: 0.6166, valid metric: 0.6514</code></pre>
</div>
</div>
<p>But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path? In this case, one approach is to split the inputs inside the <code>forward()</code> method, for example:</p>
<div id="72880ca8" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WideAndDeepV2(nn.Module):</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># same constructor as earlier, except with adjusted input sizes</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_features):</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.deep_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_features <span class="op">-</span> <span class="dv">2</span>, <span class="dv">50</span>), nn.ReLU(),</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>), nn.ReLU(),</span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">40</span>, <span class="dv">30</span>), nn.ReLU(),</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(<span class="dv">30</span> <span class="op">+</span> <span class="dv">5</span>, <span class="dv">1</span>)</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a>        X_wide <span class="op">=</span> X[:, :<span class="dv">5</span>]</span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a>        X_deep <span class="op">=</span> X[:, <span class="dv">2</span>:]</span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a>        deep_output <span class="op">=</span> <span class="va">self</span>.deep_stack(X_deep)</span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a>        wide_and_deep <span class="op">=</span> torch.concat([X_wide, deep_output], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.output_layer(wide_and_deep)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2aee7a69" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WideAndDeepV2(n_features).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="669946eb" class="cell" data-outputid="2bfafeca-2020-454d-92dc-d8b4b293e969" data-execution_count="67">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extra code: train the model, exactly our previous models</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.002</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train2(model, optimizer, mse, rmse, train_loader, valid_loader,</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a>                 n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 1.8482, train metric: 1.3598, valid metric: 0.9100
Epoch 2/20, train loss: 0.6282, train metric: 0.7927, valid metric: 0.8028
Epoch 3/20, train loss: 0.5763, train metric: 0.7591, valid metric: 0.7567
Epoch 4/20, train loss: 0.5413, train metric: 0.7356, valid metric: 0.7290
Epoch 5/20, train loss: 0.5099, train metric: 0.7142, valid metric: 0.7011
Epoch 6/20, train loss: 0.4841, train metric: 0.6958, valid metric: 0.6816
Epoch 7/20, train loss: 0.4656, train metric: 0.6824, valid metric: 0.6670
Epoch 8/20, train loss: 0.4526, train metric: 0.6728, valid metric: 0.6576
Epoch 9/20, train loss: 0.4438, train metric: 0.6662, valid metric: 0.6539
Epoch 10/20, train loss: 0.4380, train metric: 0.6618, valid metric: 0.6498
Epoch 11/20, train loss: 0.4326, train metric: 0.6577, valid metric: 0.6470
Epoch 12/20, train loss: 0.4284, train metric: 0.6546, valid metric: 0.6447
Epoch 13/20, train loss: 0.4253, train metric: 0.6521, valid metric: 0.6452
Epoch 14/20, train loss: 0.4216, train metric: 0.6494, valid metric: 0.6468
Epoch 15/20, train loss: 0.4190, train metric: 0.6473, valid metric: 0.6484
Epoch 16/20, train loss: 0.4169, train metric: 0.6458, valid metric: 0.6452
Epoch 17/20, train loss: 0.4144, train metric: 0.6438, valid metric: 0.6459
Epoch 18/20, train loss: 0.4118, train metric: 0.6417, valid metric: 0.6470
Epoch 19/20, train loss: 0.4101, train metric: 0.6404, valid metric: 0.6475
Epoch 20/20, train loss: 0.4082, train metric: 0.6389, valid metric: 0.6493</code></pre>
</div>
</div>
<p>This works fine; however, in many cases it’s preferable to just let the model take two separate tensors as input. Let’s see why and how.</p>
</section>
<section id="multiple-inputs" class="level4">
<h4 class="anchored" data-anchor-id="multiple-inputs">3.3.8.2 Multiple Inputs</h4>
<p>Some models require multiple inputs that cannot easily be combined into a single tensor. For example, the inputs may have a different number of dimensions (e.g., when you want to feed both images and text to the neural network). To make our Wide &amp; Deep model take two separate inputs, we must start by changing the model’s <code>forward()</code> method:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/emilianodesu/SIAFI-2026-1/blob/main/DL/img/wadv3.png?raw=1" class="img-fluid figure-img"></p>
<figcaption>Handling multiple inputs</figcaption>
</figure>
</div>
<div id="cac687e2" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WideAndDeepV3(nn.Module):</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># same as WideAndDeepV2</span></span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_features):</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.deep_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_features <span class="op">-</span> <span class="dv">2</span>, <span class="dv">50</span>), nn.ReLU(),</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>), nn.ReLU(),</span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">40</span>, <span class="dv">30</span>), nn.ReLU(),</span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(<span class="dv">30</span> <span class="op">+</span> <span class="dv">5</span>, <span class="dv">1</span>)</span>
<span id="cb112-11"><a href="#cb112-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-12"><a href="#cb112-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X_wide, X_deep):</span>
<span id="cb112-13"><a href="#cb112-13" aria-hidden="true" tabindex="-1"></a>        deep_output <span class="op">=</span> <span class="va">self</span>.deep_stack(X_deep)</span>
<span id="cb112-14"><a href="#cb112-14" aria-hidden="true" tabindex="-1"></a>        wide_and_deep <span class="op">=</span> torch.concat([X_wide, deep_output], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb112-15"><a href="#cb112-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.output_layer(wide_and_deep)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we need to create datasets that return the wide and deep inputs separately:</p>
<div id="6e0a3ae6" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>train_data_wd <span class="op">=</span> TensorDataset(X_train[:, :<span class="dv">5</span>], X_train[:, <span class="dv">2</span>:], y_train)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>train_loader_wd <span class="op">=</span> DataLoader(train_data_wd, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>valid_data_wd <span class="op">=</span> TensorDataset(X_valid[:, :<span class="dv">5</span>], X_valid[:, <span class="dv">2</span>:], y_valid)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>valid_loader_wd <span class="op">=</span> DataLoader(valid_data_wd, batch_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>test_data_wd <span class="op">=</span> TensorDataset(X_test[:, :<span class="dv">5</span>], X_test[:, <span class="dv">2</span>:], y_test)</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>test_loader_wd <span class="op">=</span> DataLoader(test_data_wd, batch_size<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since the data loaders now return three tensors instead of two at each iteration, we need to update the main loop in the evaluation and training functions.</p>
<p>Alternatively, since the order of the inputs matches the order of the <code>forward()</code> method’s arguments, we can use Python’s <code>*</code> operator to unpack all the inputs returned by the <code>data_loader</code> and pass them to the model. The advantage of this implementation is that it will work with models that take any number of inputs, not just two, as long as the order is correct:</p>
<div id="b46e573e" class="cell" data-outputid="280f6e8f-d24d-4e6d-cb30-cd31ac3f3f9a" data-execution_count="70">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_multi_in(model, data_loader, metric):</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>    metric.reset()  <span class="co"># reset the metric at the beginning</span></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch_wide, X_batch_deep, y_batch <span class="kw">in</span> data_loader:</span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a>            X_batch_wide <span class="op">=</span> X_batch_wide.to(device)</span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a>            X_batch_deep <span class="op">=</span> X_batch_deep.to(device)</span>
<span id="cb114-8"><a href="#cb114-8" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb114-9"><a href="#cb114-9" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch_wide, X_batch_deep)</span>
<span id="cb114-10"><a href="#cb114-10" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)  <span class="co"># update it at each iteration</span></span>
<span id="cb114-11"><a href="#cb114-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metric.compute()  <span class="co"># compute the final result at the end</span></span>
<span id="cb114-12"><a href="#cb114-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-13"><a href="#cb114-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_multi_in(model, optimizer, criterion, metric, train_loader,</span>
<span id="cb114-14"><a href="#cb114-14" aria-hidden="true" tabindex="-1"></a>                   valid_loader, n_epochs):</span>
<span id="cb114-15"><a href="#cb114-15" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">"train_losses"</span>: [], <span class="st">"train_metrics"</span>: [], <span class="st">"valid_metrics"</span>: []}</span>
<span id="cb114-16"><a href="#cb114-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb114-17"><a href="#cb114-17" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb114-18"><a href="#cb114-18" aria-hidden="true" tabindex="-1"></a>        metric.reset()</span>
<span id="cb114-19"><a href="#cb114-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">*</span>X_batch_inputs, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb114-20"><a href="#cb114-20" aria-hidden="true" tabindex="-1"></a>            model.train()</span>
<span id="cb114-21"><a href="#cb114-21" aria-hidden="true" tabindex="-1"></a>            X_batch_inputs <span class="op">=</span> [X.to(device) <span class="cf">for</span> X <span class="kw">in</span> X_batch_inputs]</span>
<span id="cb114-22"><a href="#cb114-22" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb114-23"><a href="#cb114-23" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(<span class="op">*</span>X_batch_inputs)</span>
<span id="cb114-24"><a href="#cb114-24" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb114-25"><a href="#cb114-25" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb114-26"><a href="#cb114-26" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb114-27"><a href="#cb114-27" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb114-28"><a href="#cb114-28" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb114-29"><a href="#cb114-29" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)</span>
<span id="cb114-30"><a href="#cb114-30" aria-hidden="true" tabindex="-1"></a>        mean_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb114-31"><a href="#cb114-31" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_losses"</span>].append(mean_loss)</span>
<span id="cb114-32"><a href="#cb114-32" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_metrics"</span>].append(metric.compute().item())</span>
<span id="cb114-33"><a href="#cb114-33" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"valid_metrics"</span>].append(</span>
<span id="cb114-34"><a href="#cb114-34" aria-hidden="true" tabindex="-1"></a>            evaluate_multi_in(model, valid_loader, metric).item())</span>
<span id="cb114-35"><a href="#cb114-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, "</span></span>
<span id="cb114-36"><a href="#cb114-36" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train loss: </span><span class="sc">{</span>history[<span class="st">'train_losses'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb114-37"><a href="#cb114-37" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train metric: </span><span class="sc">{</span>history[<span class="st">'train_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb114-38"><a href="#cb114-38" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"valid metric: </span><span class="sc">{</span>history[<span class="st">'valid_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb114-39"><a href="#cb114-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb114-40"><a href="#cb114-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-41"><a href="#cb114-41" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb114-42"><a href="#cb114-42" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb114-43"><a href="#cb114-43" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WideAndDeepV3(n_features).to(device)</span>
<span id="cb114-44"><a href="#cb114-44" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb114-45"><a href="#cb114-45" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb114-46"><a href="#cb114-46" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb114-47"><a href="#cb114-47" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train_multi_in(model, optimizer, mse, rmse, train_loader_wd,</span>
<span id="cb114-48"><a href="#cb114-48" aria-hidden="true" tabindex="-1"></a>                         valid_loader_wd, n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892
Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455
Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374
Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512
Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305
Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287
Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252
Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158
Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407
Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063
Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974
Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888
Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981
Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842
Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410
Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747
Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686
Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679
Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621
Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690</code></pre>
</div>
</div>
<p>When your model has many inputs, it’s easy to make a mistake and mix up the order of the inputs, which can lead to hard-to-debug issues. To avoid this, it can be a good idea to name each input. For this, you can define a custom dataset that returns a dictionary from input names to input values, like this:</p>
<div id="3a9a0b2d" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WideAndDeepDataset(torch.utils.data.Dataset):</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X_wide, X_deep, y):</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_wide <span class="op">=</span> X_wide</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_deep <span class="op">=</span> X_deep</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.y)</span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>        input_dict <span class="op">=</span> {<span class="st">"X_wide"</span>: <span class="va">self</span>.X_wide[idx], <span class="st">"X_deep"</span>: <span class="va">self</span>.X_deep[idx]}</span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> input_dict, <span class="va">self</span>.y[idx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then create the datasets and data loaders:</p>
<div id="d72f4f95" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>train_data_named <span class="op">=</span> WideAndDeepDataset(</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>    X_wide<span class="op">=</span>X_train[:, :<span class="dv">5</span>], X_deep<span class="op">=</span>X_train[:, <span class="dv">2</span>:], y<span class="op">=</span>y_train)</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>train_loader_named <span class="op">=</span> DataLoader(train_data_named, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>valid_data_named <span class="op">=</span> WideAndDeepDataset(</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>    X_wide<span class="op">=</span>X_valid[:, :<span class="dv">5</span>], X_deep<span class="op">=</span>X_valid[:, <span class="dv">2</span>:], y<span class="op">=</span>y_valid)</span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>valid_loader_named <span class="op">=</span> DataLoader(valid_data_named, batch_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>test_data_named <span class="op">=</span> WideAndDeepDataset(</span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>    X_wide<span class="op">=</span>X_test[:, :<span class="dv">5</span>], X_deep<span class="op">=</span>X_test[:, <span class="dv">2</span>:], y<span class="op">=</span>y_test)</span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>test_loader_named <span class="op">=</span> DataLoader(test_data_named, batch_size<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once again, we also need to update the main loop in the evaluation and training functions:</p>
<div id="78e78209" class="cell" data-outputid="d25e71c8-c5e9-42ff-a095-b78235ec8d44" data-execution_count="73">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_named(model, data_loader, metric):</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>    metric.reset()  <span class="co"># reset the metric at the beginning</span></span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, y_batch <span class="kw">in</span> data_loader:</span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {name: X.to(device) <span class="cf">for</span> name, X <span class="kw">in</span> inputs.items()}</span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_wide<span class="op">=</span>inputs[<span class="st">"X_wide"</span>], X_deep<span class="op">=</span>inputs[<span class="st">"X_deep"</span>])</span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)</span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metric.compute()  <span class="co"># compute the final result at the end</span></span>
<span id="cb118-11"><a href="#cb118-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-12"><a href="#cb118-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_named(model, optimizer, criterion, metric, train_loader,</span>
<span id="cb118-13"><a href="#cb118-13" aria-hidden="true" tabindex="-1"></a>                   valid_loader, n_epochs):</span>
<span id="cb118-14"><a href="#cb118-14" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">"train_losses"</span>: [], <span class="st">"train_metrics"</span>: [], <span class="st">"valid_metrics"</span>: []}</span>
<span id="cb118-15"><a href="#cb118-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb118-16"><a href="#cb118-16" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb118-17"><a href="#cb118-17" aria-hidden="true" tabindex="-1"></a>        metric.reset()</span>
<span id="cb118-18"><a href="#cb118-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb118-19"><a href="#cb118-19" aria-hidden="true" tabindex="-1"></a>            model.train()</span>
<span id="cb118-20"><a href="#cb118-20" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {name: X.to(device) <span class="cf">for</span> name, X <span class="kw">in</span> inputs.items()}</span>
<span id="cb118-21"><a href="#cb118-21" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb118-22"><a href="#cb118-22" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb118-23"><a href="#cb118-23" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb118-24"><a href="#cb118-24" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb118-25"><a href="#cb118-25" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb118-26"><a href="#cb118-26" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb118-27"><a href="#cb118-27" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb118-28"><a href="#cb118-28" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)</span>
<span id="cb118-29"><a href="#cb118-29" aria-hidden="true" tabindex="-1"></a>        mean_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb118-30"><a href="#cb118-30" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_losses"</span>].append(mean_loss)</span>
<span id="cb118-31"><a href="#cb118-31" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_metrics"</span>].append(metric.compute().item())</span>
<span id="cb118-32"><a href="#cb118-32" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"valid_metrics"</span>].append(</span>
<span id="cb118-33"><a href="#cb118-33" aria-hidden="true" tabindex="-1"></a>            evaluate_named(model, valid_loader, metric).item())</span>
<span id="cb118-34"><a href="#cb118-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, "</span></span>
<span id="cb118-35"><a href="#cb118-35" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train loss: </span><span class="sc">{</span>history[<span class="st">'train_losses'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb118-36"><a href="#cb118-36" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train metric: </span><span class="sc">{</span>history[<span class="st">'train_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb118-37"><a href="#cb118-37" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"valid metric: </span><span class="sc">{</span>history[<span class="st">'valid_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb118-38"><a href="#cb118-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb118-39"><a href="#cb118-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-40"><a href="#cb118-40" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb118-41"><a href="#cb118-41" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb118-42"><a href="#cb118-42" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WideAndDeepV3(n_features).to(device)</span>
<span id="cb118-43"><a href="#cb118-43" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb118-44"><a href="#cb118-44" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb118-45"><a href="#cb118-45" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb118-46"><a href="#cb118-46" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train_named(model, optimizer, mse, rmse, train_loader_named,</span>
<span id="cb118-47"><a href="#cb118-47" aria-hidden="true" tabindex="-1"></a>                      valid_loader_named, n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892
Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455
Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374
Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512
Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305
Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287
Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252
Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158
Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407
Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063
Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974
Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888
Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981
Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842
Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410
Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747
Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686
Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679
Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621
Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690</code></pre>
</div>
</div>
<p>Alternatively, since all the input names match the <code>forward()</code> method’s argument names, we can use Python’s <code>**</code> operator to unpack all the tensors in the <code>inputs</code> dictionary and pass them as named arguments to the model: <code>y_pred = model(**inputs)</code>.</p>
<p>Now that you know how to build sequential and nonsequential models with one or more inputs, let’s look at models with multiple outputs.</p>
</section>
<section id="multiple-outputs" class="level4">
<h4 class="anchored" data-anchor-id="multiple-outputs">3.3.8.3 Multiple Outputs</h4>
<p>There are many use cases where you may need a neural net with multiple outputs:</p>
<ul>
<li>The task may demand it. For instance, you may want to locate and classify the main object in a picture. This is both a regression task and a classification task.</li>
<li>Similarly, you may have multiple independent tasks based on the same data. Sure, you could train one neural network per task, but in many cases you will get better results on all tasks by training a single neural network with one output per task. This is because the neural network can learn features in the data that are useful across tasks. For example, you could perform <em>multitask classification</em> on pictures of faces, using one output to classify the person’s facial expression (smiling, surprised, etc.) and another output to identify whether they are wearing glasses or not.</li>
<li>Another use case is regularization (i.e., a training constraint whose objective is to reduce overfitting and thus improve the model’s ability to generalize). For example, you may want to add an auxiliary output in a neural network architecture to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of the network.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/emilianodesu/SIAFI-2026-1/blob/main/DL/img/multiout.png?raw=1" class="img-fluid figure-img"></p>
<figcaption>Handling multiple outputs, in this example to add an auxiliary output for regularization</figcaption>
</figure>
</div>
<p>Let’s add an auxiliary output to our Wide &amp; Deep model to ensure the deep part can make good predictions on its own. Since the deep stack’s output dimension is 40, and the targets have a single dimension, we must add an <code>nn.Linear</code> layer for the auxiliary output to go from 40 dimensions down to 1. We also need to make the <code>forward()</code> method compute the auxiliary output, and return both the main output and the auxiliary output:</p>
<div id="b32f6fc0" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WideAndDeepV4(nn.Module):</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># same as earlier</span></span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_features):</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.deep_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_features <span class="op">-</span> <span class="dv">2</span>, <span class="dv">50</span>), nn.ReLU(),</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">50</span>, <span class="dv">40</span>), nn.ReLU(),</span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">40</span>, <span class="dv">30</span>), nn.ReLU(),</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(<span class="dv">30</span> <span class="op">+</span> <span class="dv">5</span>, <span class="dv">1</span>)</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.aux_output_layer <span class="op">=</span> nn.Linear(<span class="dv">30</span>, <span class="dv">1</span>)</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X_wide, X_deep):</span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a>        deep_output <span class="op">=</span> <span class="va">self</span>.deep_stack(X_deep)</span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>        wide_and_deep <span class="op">=</span> torch.concat([X_wide, deep_output], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>        main_output <span class="op">=</span> <span class="va">self</span>.output_layer(wide_and_deep)</span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>        aux_output <span class="op">=</span> <span class="va">self</span>.aux_output_layer(deep_output)</span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> main_output, aux_output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we need to update the main loop in the training function:</p>
<div id="93cfb8ea" class="cell" data-outputid="2c6ad2eb-dbbb-4804-b87c-84ad1489e35e" data-execution_count="75">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchmetrics</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_multi_out(model, data_loader, metric):</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    metric.reset()</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, y_batch <span class="kw">in</span> data_loader:</span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {name: X.to(device) <span class="cf">for</span> name, X <span class="kw">in</span> inputs.items()}</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>            y_pred, _ <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)</span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metric.compute()</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_multi_out(model, optimizer, criterion, metric, train_loader,</span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a>                   valid_loader, n_epochs):</span>
<span id="cb121-16"><a href="#cb121-16" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">"train_losses"</span>: [], <span class="st">"train_metrics"</span>: [], <span class="st">"valid_metrics"</span>: []}</span>
<span id="cb121-17"><a href="#cb121-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb121-18"><a href="#cb121-18" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb121-19"><a href="#cb121-19" aria-hidden="true" tabindex="-1"></a>        metric.reset()</span>
<span id="cb121-20"><a href="#cb121-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb121-21"><a href="#cb121-21" aria-hidden="true" tabindex="-1"></a>            model.train()</span>
<span id="cb121-22"><a href="#cb121-22" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {name: X.to(device) <span class="cf">for</span> name, X <span class="kw">in</span> inputs.items()}</span>
<span id="cb121-23"><a href="#cb121-23" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb121-24"><a href="#cb121-24" aria-hidden="true" tabindex="-1"></a>            y_pred, y_pred_aux <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb121-25"><a href="#cb121-25" aria-hidden="true" tabindex="-1"></a>            main_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb121-26"><a href="#cb121-26" aria-hidden="true" tabindex="-1"></a>            aux_loss <span class="op">=</span> criterion(y_pred_aux, y_batch)</span>
<span id="cb121-27"><a href="#cb121-27" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="fl">0.8</span> <span class="op">*</span> main_loss <span class="op">+</span> <span class="fl">0.2</span> <span class="op">*</span> aux_loss</span>
<span id="cb121-28"><a href="#cb121-28" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb121-29"><a href="#cb121-29" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb121-30"><a href="#cb121-30" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb121-31"><a href="#cb121-31" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb121-32"><a href="#cb121-32" aria-hidden="true" tabindex="-1"></a>            metric.update(y_pred, y_batch)</span>
<span id="cb121-33"><a href="#cb121-33" aria-hidden="true" tabindex="-1"></a>        mean_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb121-34"><a href="#cb121-34" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_losses"</span>].append(mean_loss)</span>
<span id="cb121-35"><a href="#cb121-35" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_metrics"</span>].append(metric.compute().item())</span>
<span id="cb121-36"><a href="#cb121-36" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"valid_metrics"</span>].append(</span>
<span id="cb121-37"><a href="#cb121-37" aria-hidden="true" tabindex="-1"></a>            evaluate_multi_out(model, valid_loader, metric).item())</span>
<span id="cb121-38"><a href="#cb121-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, "</span></span>
<span id="cb121-39"><a href="#cb121-39" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train loss: </span><span class="sc">{</span>history[<span class="st">'train_losses'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb121-40"><a href="#cb121-40" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"train metric: </span><span class="sc">{</span>history[<span class="st">'train_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">, "</span></span>
<span id="cb121-41"><a href="#cb121-41" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"valid metric: </span><span class="sc">{</span>history[<span class="st">'valid_metrics'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb121-42"><a href="#cb121-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb121-43"><a href="#cb121-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-44"><a href="#cb121-44" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb121-45"><a href="#cb121-45" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb121-46"><a href="#cb121-46" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WideAndDeepV4(n_features).to(device)</span>
<span id="cb121-47"><a href="#cb121-47" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb121-48"><a href="#cb121-48" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb121-49"><a href="#cb121-49" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> torchmetrics.MeanSquaredError(squared<span class="op">=</span><span class="va">False</span>).to(device)</span>
<span id="cb121-50"><a href="#cb121-50" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train_multi_out(model, optimizer, mse, rmse, train_loader_named,</span>
<span id="cb121-51"><a href="#cb121-51" aria-hidden="true" tabindex="-1"></a>                          valid_loader_named, n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 1.0693, train metric: 0.9506, valid metric: 0.7085
Epoch 2/20, train loss: 0.5817, train metric: 0.6946, valid metric: 0.6607
Epoch 3/20, train loss: 0.5010, train metric: 0.6581, valid metric: 0.6425
Epoch 4/20, train loss: 0.4690, train metric: 0.6497, valid metric: 0.6654
Epoch 5/20, train loss: 0.4503, train metric: 0.6420, valid metric: 0.6338
Epoch 6/20, train loss: 0.4387, train metric: 0.6373, valid metric: 0.6563
Epoch 7/20, train loss: 0.4315, train metric: 0.6330, valid metric: 0.6193
Epoch 8/20, train loss: 0.4249, train metric: 0.6302, valid metric: 0.6167
Epoch 9/20, train loss: 0.4116, train metric: 0.6202, valid metric: 0.6450
Epoch 10/20, train loss: 0.4085, train metric: 0.6198, valid metric: 0.5938
Epoch 11/20, train loss: 0.4073, train metric: 0.6197, valid metric: 0.5959
Epoch 12/20, train loss: 0.3914, train metric: 0.6078, valid metric: 0.6073
Epoch 13/20, train loss: 0.3847, train metric: 0.6033, valid metric: 0.5815
Epoch 14/20, train loss: 0.3849, train metric: 0.6048, valid metric: 0.6042
Epoch 15/20, train loss: 0.3744, train metric: 0.5965, valid metric: 0.5740
Epoch 16/20, train loss: 0.3690, train metric: 0.5928, valid metric: 0.6111
Epoch 17/20, train loss: 0.3675, train metric: 0.5923, valid metric: 0.5766
Epoch 18/20, train loss: 0.3606, train metric: 0.5869, valid metric: 0.5782
Epoch 19/20, train loss: 0.3604, train metric: 0.5867, valid metric: 0.5664
Epoch 20/20, train loss: 0.3566, train metric: 0.5837, valid metric: 0.5654</code></pre>
</div>
</div>
<p>Notice that the model now returns both the main predictions <code>y_pred</code> and the auxiliary predictions <code>y_pred_aux</code>. In this example, we can use the same targets and the same loss function to compute the main output’s loss and the auxiliary output’s loss. In other cases, you may have different targets and loss functions for each output, in which case you would need to create a custom dataset to return all the necessary targets. Once we have a loss for each output, we must combine them into a single loss that will be minimized by gradient descent. In general, this final loss is just a weighted sum of all the output losses. In this example, we use a higher weight for the main loss (0.8), because that’s what we care about the most, and a lower weight for the auxiliary loss (0.2). This ratio is a regularization hyperparameter that you can tune.</p>
<p>We also need to update the main loop in the evaluation function. However, in this case we can just ignore the auxiliary output, since we only really care about the main output—the auxiliary output is just there for regularization during training.</p>
<p>You can now build and train all sorts of neural net architectures, combining predefined modules and custom modules in any way you please, and with any number of inputs and outputs. The flexibility of neural networks is one of their main qualities. But so far we have only tackled a regression task, so let’s now turn to classification.</p>
</section>
</section>
<section id="building-an-image-classifier-with-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="building-an-image-classifier-with-pytorch">3.3.9 Building an Image Classifier with PyTorch</h3>
<section id="using-torchvision-to-load-the-dataset" class="level4">
<h4 class="anchored" data-anchor-id="using-torchvision-to-load-the-dataset">3.3.9.1 Using TorchVision to Load the Dataset</h4>
<p>We will tackle the Fashion MNIST dataset, so the first thing we need to do is to download the dataset. The TorchVision library is an important part of the PyTorch ecosystem: it provides many tools for computer vision, including utility functions to download common datasets, such as MNIST or Fashion MNIST, as well as pretrained models for various computer vision tasks, functions to transform images (e.g., crop, rotate, resize, etc.), and more. It is preinstalled on Colab, so let’s go ahead and use it to load Fashion MNIST. It is already split into a training set (60,000 images) and a test set (10,000 images), but we’ll hold out the last 5,000 images from the training set for validation, using PyTorch’s <code>random_split()</code> function:</p>
<div id="2d4486f1" class="cell" data-outputid="83dc6901-6533-4f49-a82d-e068a3141332" data-execution_count="76">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms.v2 <span class="im">as</span> T</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>toTensor <span class="op">=</span> T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale<span class="op">=</span><span class="va">True</span>)])</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>train_and_valid_data <span class="op">=</span> torchvision.datasets.FashionMNIST(</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"datasets"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>toTensor)</span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> torchvision.datasets.FashionMNIST(</span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"datasets"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>toTensor)</span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true" tabindex="-1"></a>train_data, valid_data <span class="op">=</span> torch.utils.data.random_split(</span>
<span id="cb123-13"><a href="#cb123-13" aria-hidden="true" tabindex="-1"></a>    train_and_valid_data, [<span class="dv">55_000</span>, <span class="dv">5_000</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 26.4M/26.4M [00:02&lt;00:00, 11.9MB/s]
100%|██████████| 29.5k/29.5k [00:00&lt;00:00, 205kB/s]
100%|██████████| 4.42M/4.42M [00:01&lt;00:00, 3.78MB/s]
100%|██████████| 5.15k/5.15k [00:00&lt;00:00, 14.0MB/s]</code></pre>
</div>
</div>
<p>After the imports and before loading the datasets, we create a <code>toTensor</code> object. What’s that about? Well, by default, the <code>FashionMNIST</code> class loads images as PIL (Python Image Library) images, with integer pixel values ranging from 0 to 255. But we need PyTorch float tensors instead, with scaled pixel values. Luckily, TorchVision datasets accept a <code>transform</code> argument which lets you pass a preprocessing function that will get executed on the fly whenever the data is accessed (there’s also a <code>target_transform</code> argument if you need to preprocess the targets). TorchVision provides many transform objects that you can use for this (most of these transforms are PyTorch modules).</p>
<p>In this code, we create a <code>Compose</code> transform to chain two transforms: a <code>ToImage</code> transform followed by a <code>ToDtype</code> transform. <code>ToImage</code> converts various formats—including PIL images, NumPy arrays, and tensors—to TorchVision’s <code>Image</code> class, which is a subclass of <code>Tensor</code>. The <code>ToDtype</code> transform converts the data type, in this case to 32-bit floats. We also set its <code>scale</code> argument to <code>True</code> to ensure the values get scaled between 0.0 and 1.0.</p>
<p>Next, we load the dataset: first the training and validation data, then the test data. The <code>root</code> argument is the path to the directory where TorchVision will create a subdirectory for the Fashion MNIST dataset. The <code>train</code> argument indicates whether you want to load the training set (<code>True</code> by default) or the test set. The <code>download</code> argument indicates whether to download the dataset if it cannot be found locally (<code>False</code> by default). And we also set <code>transform=toTensor</code> to use our custom preprocessing pipeline.</p>
<p>As usual, we must create data loaders:</p>
<div id="357f87b0" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>valid_loader <span class="op">=</span> DataLoader(valid_data, batch_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s look at the first image in the training set:</p>
<div id="0a051881" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>X_sample, y_sample <span class="op">=</span> train_data[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="568bbd3a" class="cell" data-outputid="7c32d6cd-a215-4f94-85c1-632c2690e761" data-execution_count="79">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>X_sample.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>torch.Size([1, 28, 28])</code></pre>
</div>
</div>
<p>Each image tensor has 3 dimensions, and its shape is: <code>[1, 28, 28]</code>. The first dimension is the <em>channel</em> dimension. For grayscale images, there is a single channel (color images usually have three channels). The other two dimensions are the height and width dimensions. For example, <code>X_sample[0, 2, 4]</code> represents the pixel located in channel 0, row 2, column 4. In Fashion MNIST, a larger value means a darker pixel.</p>
<div id="55b54666" class="cell" data-outputid="d2b39033-734e-414f-d97a-97ded557481b" data-execution_count="80">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>X_sample.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>torch.float32</code></pre>
</div>
</div>
<p>As for the targets, they are integers from 0 to 9, and we can interpret them using the <code>class_names</code> array. In fact, many datasets—including <code>FashionMNIST</code>—have a classes attribute containing the list of class names. For example, here’s how we can tell that the sample image represents an ankle boot:</p>
<div id="ccdef453" class="cell" data-outputid="a5c3d56d-cc2a-42e9-bce6-a610ae15b895" data-execution_count="81">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>train_and_valid_data.classes[y_sample]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>'Ankle boot'</code></pre>
</div>
</div>
</section>
<section id="building-the-classifier" class="level4">
<h4 class="anchored" data-anchor-id="building-the-classifier">3.3.9.2 Building the Classifier</h4>
<p>Let’s build a custom module for a classification MLP with two hidden layers:</p>
<div id="c4ed7dca" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageClassifier(nn.Module):</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_hidden1, n_hidden2, n_classes):</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> nn.Sequential(</span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_inputs, n_hidden1),</span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_hidden1, n_hidden2),</span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_hidden2, n_classes)</span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-13"><a href="#cb133-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb133-14"><a href="#cb133-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.mlp(X)</span>
<span id="cb133-15"><a href="#cb133-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-16"><a href="#cb133-16" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb133-17"><a href="#cb133-17" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ImageClassifier(n_inputs<span class="op">=</span><span class="dv">1</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, n_hidden1<span class="op">=</span><span class="dv">300</span>, n_hidden2<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb133-18"><a href="#cb133-18" aria-hidden="true" tabindex="-1"></a>                        n_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span>
<span id="cb133-19"><a href="#cb133-19" aria-hidden="true" tabindex="-1"></a>xentropy <span class="op">=</span> nn.CrossEntropyLoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are a few things to note in this code:</p>
<ul>
<li>First, the model is composed of a single sequence of layers, which is why we used the <code>nn.Sequential</code> module. We did not have to create a custom module; we could have written <code>model = nn.Sequential(...)</code> instead, but it’s generally preferable to wrap your models in custom modules, as it makes your code easier to deploy and reuse, and it’s also easier to tune the hyperparameters.</li>
<li>The model starts with an <code>nn.Flatten</code> layer: this layer does not have any parameters, it just reshapes each input sample to a single dimension, which is needed for the <code>nn.Linear</code> layers. For example, a batch of 32 Fashion MNIST images has a shape of <code>[32, 1, 28, 28]</code>, but after going through the <code>nn.Flatten</code> layer, it ends up with a shape of <code>[32, 784]</code> (since 28 × 28 = 784).</li>
<li>The first hidden layer must have the correct number of inputs (28 × 28 = 784), and the output layer must have the correct number of outputs (10, one per class).</li>
<li>We use a ReLU activation function after each hidden layer, and no activation function at all after the output layer.</li>
<li>Since this is a multiclass classification task, we use <code>nn.CrossEntropyLoss</code>. It accepts either class indices as targets (as in this example), or class probabilities (such as one-hot vectors).</li>
</ul>
<p>PyTorch’s <code>nn.CrossEntropyLoss</code> computes the cross-entropy loss directly from the logits (i.e., the class scores), rather than from the class probabilities. This bypasses some costly computations during training (e.g., logarithms and exponentials that cancel out), saving both compute and RAM. It’s also more numerically stable. However, the downside is that the model must output logits, which means that we will have to call the softmax function manually on the logits whenever we want class probabilities, as we will see shortly.</p>
<p><strong>Note</strong>: For binary classification tasks, you must use a single output neuron in the output layer, and use the <code>nn.BCEWithLogitsLoss</code> (BCE stands for binary cross-entropy). The model outputs logits, so you must apply the sigmoid function to get estimated probabilities (for the positive class). Alternatively, you can add the <code>nn.Sigmoid</code> activation function to the output layer, and use the <code>nn.BCELoss</code>: the model will then output estimated probabilities directly (but it’s a bit slower and less numerically stable).</p>
<p>For multilabel binary classification, the only difference is that you must have one neuron per label in the output layer.</p>
<p>Now we can train the model as usual (e.g., using the train() function with an SGD optimizer). To evaluate the model, we can use the Accuracy streaming metric from the torchmetrics library, and move it to the GPU:</p>
<div id="1c4150f1" class="cell" data-outputid="0e527fd5-e8df-458f-dd2f-2402e7fd9573" data-execution_count="83">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> torchmetrics.Accuracy(task<span class="op">=</span><span class="st">"multiclass"</span>, num_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader,</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>           n_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20, train loss: 0.6058, train metric: 0.7816, valid metric: 0.8416
Epoch 2/20, train loss: 0.4059, train metric: 0.8497, valid metric: 0.8372
Epoch 3/20, train loss: 0.3633, train metric: 0.8663, valid metric: 0.8530
Epoch 4/20, train loss: 0.3359, train metric: 0.8762, valid metric: 0.8660
Epoch 5/20, train loss: 0.3147, train metric: 0.8835, valid metric: 0.8754
Epoch 6/20, train loss: 0.2991, train metric: 0.8881, valid metric: 0.8666
Epoch 7/20, train loss: 0.2859, train metric: 0.8916, valid metric: 0.8622
Epoch 8/20, train loss: 0.2745, train metric: 0.8971, valid metric: 0.8722
Epoch 9/20, train loss: 0.2639, train metric: 0.9007, valid metric: 0.8834
Epoch 10/20, train loss: 0.2531, train metric: 0.9041, valid metric: 0.8810
Epoch 11/20, train loss: 0.2463, train metric: 0.9068, valid metric: 0.8850
Epoch 12/20, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8910
Epoch 13/20, train loss: 0.2303, train metric: 0.9125, valid metric: 0.8870
Epoch 14/20, train loss: 0.2235, train metric: 0.9144, valid metric: 0.8734
Epoch 15/20, train loss: 0.2154, train metric: 0.9184, valid metric: 0.8788
Epoch 16/20, train loss: 0.2089, train metric: 0.9207, valid metric: 0.8826
Epoch 17/20, train loss: 0.2030, train metric: 0.9234, valid metric: 0.8906
Epoch 18/20, train loss: 0.1989, train metric: 0.9242, valid metric: 0.8884
Epoch 19/20, train loss: 0.1924, train metric: 0.9271, valid metric: 0.8818
Epoch 20/20, train loss: 0.1888, train metric: 0.9282, valid metric: 0.8716</code></pre>
</div>
</div>
<p>The model reaches around 92.8% accuracy on the training set, and 87.2% accuracy on the validation set (the results might differ a bit depending on the hardware accelerator you use). This means there’s a little bit of overfitting going on, so you may want to reduce the number of neurons or add some regularization.</p>
<p>Now that the model is trained, we can use it to make predictions on new images. As an example, let’s make predictions for the first batch in the validation set, and look at the results for the first three images:</p>
<div id="9c9691d6" class="cell" data-outputid="99b46bd6-4446-4bb4-e1e3-c8bfc6fcc578" data-execution_count="84">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>X_new, y_new <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(valid_loader))</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> X_new[:<span class="dv">3</span>].to(device)</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>    y_pred_logits <span class="op">=</span> model(X_new)</span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> y_pred_logits.argmax(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># index of the largest logit</span></span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>tensor([7, 4, 2], device='cuda:0')</code></pre>
</div>
</div>
<div id="f9bdbeef" class="cell" data-outputid="21407b70-53e1-452e-d44e-b64723a520dd" data-execution_count="85">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>[train_and_valid_data.classes[index] <span class="cf">for</span> index <span class="kw">in</span> y_pred]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>['Sneaker', 'Coat', 'Pullover']</code></pre>
</div>
</div>
<div id="6006f274" class="cell" data-outputid="a792ec41-b621-4f79-9e76-b32cf25eb248" data-execution_count="86">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>y_new[:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([7, 4, 2])</code></pre>
</div>
</div>
<p>For each image, the predicted class is the one with the highest logit. In this example, all three predictions are correct!</p>
<p>But what if we want the model’s estimated probabilities? For this, we need to compute the softmax of the logits manually, since the model does not include the softmax activation function on the output layer, as we discussed earlier. We could create an <code>nn.Softmax</code> module and pass it the logits, but we can also just call the <code>softmax()</code> function, which is just one of many functions you will find in the <code>torch.nn.functional</code> module (by convention, this module is usually imported as <code>F</code>). It doesn’t make much difference, it just avoids creating a module instance that we don’t need:</p>
<div id="8960e740" class="cell" data-outputid="1a81c626-9546-41fa-8f1a-11ccc82dca48" data-execution_count="87">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>y_proba <span class="op">=</span> F.softmax(y_pred_logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> device <span class="op">==</span> <span class="st">"mps"</span>:</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>    y_proba <span class="op">=</span> y_proba.cpu()</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>y_proba.<span class="bu">round</span>(decimals<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.9110, 0.0000,
         0.0880],
        [0.0000, 0.0000, 0.0040, 0.0000, 0.9960, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000],
        [0.0000, 0.0000, 0.6250, 0.0000, 0.3350, 0.0000, 0.0390, 0.0000, 0.0000,
         0.0000]], device='cuda:0')</code></pre>
</div>
</div>
<p>The model is very confident about the first two predictions.</p>
<p><strong>Tip</strong>: If you wish to apply label smoothing during training, just set the label_smoothing hyperparameter of the nn.CrossEntropyLoss to the amount of smoothing you wish, between 0 and 1 (e.g., 0.05).</p>
<p>It can often be useful to get the model’s top <em>k</em> predictions. For this, we can use the <code>torch.topk()</code> function, which returns a tuple containing both the top <em>k</em> values and their indices:</p>
<div id="0bf6737d" class="cell" data-outputid="7b875ae1-b43c-4896-f057-5b336bcd484f" data-execution_count="88">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>y_top4_values, y_top4_indices <span class="op">=</span> torch.topk(y_pred_logits, k<span class="op">=</span><span class="dv">4</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>y_top4_probas <span class="op">=</span> F.softmax(y_top4_values, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> device <span class="op">==</span> <span class="st">"mps"</span>:</span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>    y_top4_probas <span class="op">=</span> y_top4_probas.cpu()</span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>y_top4_probas.<span class="bu">round</span>(decimals<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>tensor([[0.9110, 0.0880, 0.0010, 0.0000],
        [0.9960, 0.0040, 0.0000, 0.0000],
        [0.6250, 0.3350, 0.0390, 0.0000]], device='cuda:0')</code></pre>
</div>
</div>
<div id="1b44259e" class="cell" data-outputid="689066c2-10b3-4b55-94c2-1d794e0e8eae" data-execution_count="89">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>y_top4_indices</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>tensor([[7, 9, 5, 8],
        [4, 2, 6, 0],
        [2, 4, 6, 0]], device='cuda:0')</code></pre>
</div>
</div>
<p>For the first image, the model’s best guess is class 7 (Sneaker) with 91.1% confidence, its second best guess is class 9 (Ankle boot) with 8.8% confidence, and so on.</p>
<p><strong>Tip</strong>: The Fashion MNIST dataset is balanced, meaning it has the same number of instances of each class. When dealing with an unbalanced dataset, you should generally give more weight to the rare classes and less weight to the frequent ones, or else your model will be biased toward the more frequent classes. You can do this by setting the <code>weight</code> argument of the <code>nn.CrossEntropyLoss</code>. For example, if there are three classes with 900, 700, and 400 instances, respectively (i.e., 2000 instances in total), then the respective weights should be 2000/900, 2000/700, and 2000/400. It’s preferable to normalize these weights to ensure they add up to 1, so in this example you would set <code>weight=torch.tensor([0.2205, 0.2835, 0.4961])</code>.</p>
</section>
</section>
<section id="fine-tuning-with-optuna" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-with-optuna">3.3.10 Fine-Tuning with Optuna</h3>
<p>What if you want to go further and automatically search for good hyperparameter values? You will usually get great results by using a dedicated fine-tuning library such as <a href="https://optuna.org">Optuna</a>, <a href="https://docs.ray.io">Ray Tune</a>, or <a href="https://hyperopt.github.io/hyperopt">Hyperopt</a>. These libraries offer several powerful tuning strategies, and they’re highly customizable.</p>
<p>Let’s look at an example using Optuna. It is not preinstalled on Colab, so we need to install it using</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install optuna</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s tune the learning rate and the number of neurons in the hidden layers (for simplicity, we will use the same number of neurons in both hidden layers). First, we need to define a function that Optuna will call many times to perform hyperparameter tuning: this function must take a <code>Trial</code> object and use it to ask Optuna for hyperparameter values, and then use these hyperparameter values to build and train a model. Finally, the function must evaluate the model (typically on the validation set) and return the metric:</p>
<div id="084499f3" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> trial.suggest_float(<span class="st">"learning_rate"</span>, <span class="fl">1e-5</span>, <span class="fl">1e-1</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a>    n_hidden <span class="op">=</span> trial.suggest_int(<span class="st">"n_hidden"</span>, <span class="dv">20</span>, <span class="dv">300</span>)</span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ImageClassifier(n_inputs<span class="op">=</span><span class="dv">1</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, n_hidden1<span class="op">=</span>n_hidden,</span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>                            n_hidden2<span class="op">=</span>n_hidden, n_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a>    xentropy <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> torchmetrics.Accuracy(task<span class="op">=</span><span class="st">"multiclass"</span>, num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb149-11"><a href="#cb149-11" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> accuracy.to(device)</span>
<span id="cb149-12"><a href="#cb149-12" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> train2(model, optimizer, xentropy, accuracy, train_loader,</span>
<span id="cb149-13"><a href="#cb149-13" aria-hidden="true" tabindex="-1"></a>                     valid_loader, n_epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb149-14"><a href="#cb149-14" aria-hidden="true" tabindex="-1"></a>    validation_accuracy <span class="op">=</span> <span class="bu">max</span>(history[<span class="st">"valid_metrics"</span>])</span>
<span id="cb149-15"><a href="#cb149-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> validation_accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>suggest_float()</code> and <code>suggest_int()</code> methods let us ask Optuna for a good hyperparameter value in a given range (Optuna also provides a <code>suggest_categorical()</code> method). For the <code>learning_rate</code> hyperparameter, we ask for a value between <span class="math inline">\(10^{-5}\)</span> and <span class="math inline">\(10^{-1}\)</span>, and since we don’t know what the optimal scale is, we add <code>log=True</code>: this will make Optuna sample values from a log distribution, which makes it explore all possible scales. If we used the default uniform distribution instead, Optuna would be very unlikely to explore tiny values.</p>
<p>To start hyperparameter tuning, we create a <code>Study</code> object and call its <code>optimize()</code> method, passing it the objective function we just defined, as well as the number of trials to run (i.e., the number of times Optuna should call the objective function). Since our objective function returns a score—higher is better—we set <code>direction="maximize"</code> when creating the study (by default, Optuna tries to <em>minimize</em> the objective). To ensure reproducibility, we also set PyTorch’s random seed, as well as the random seed used by Optuna’s sampler:</p>
<div id="23a2ffb8" class="cell" data-outputid="d57c7aa7-aed1-4bf9-e0f5-889079f7f843" data-execution_count="91">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> optuna.samplers.TPESampler(seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">"maximize"</span>, sampler<span class="op">=</span>sampler)</span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:46:07,394] A new study created in memory with name: no-name-2d8208ff-1974-4989-8640-7ff0a6153d59</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860
Epoch 2/10, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500
Epoch 3/10, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554
Epoch 4/10, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562
Epoch 5/10, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026
Epoch 6/10, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228
Epoch 7/10, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326
Epoch 8/10, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372
Epoch 9/10, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:48:36,917] Trial 0 finished with value: 0.6435999870300293 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.6435999870300293.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 10/10, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436
Epoch 1/10, train loss: 1.1459, train metric: 0.6229, valid metric: 0.7338
Epoch 2/10, train loss: 0.6108, train metric: 0.7841, valid metric: 0.7992
Epoch 3/10, train loss: 0.5203, train metric: 0.8169, valid metric: 0.8094
Epoch 4/10, train loss: 0.4810, train metric: 0.8302, valid metric: 0.8310
Epoch 5/10, train loss: 0.4557, train metric: 0.8404, valid metric: 0.8352
Epoch 6/10, train loss: 0.4387, train metric: 0.8460, valid metric: 0.8442
Epoch 7/10, train loss: 0.4240, train metric: 0.8512, valid metric: 0.8408
Epoch 8/10, train loss: 0.4123, train metric: 0.8566, valid metric: 0.8514
Epoch 9/10, train loss: 0.3998, train metric: 0.8601, valid metric: 0.8532</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:51:07,017] Trial 1 finished with value: 0.8547999858856201 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.8547999858856201.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 10/10, train loss: 0.3897, train metric: 0.8638, valid metric: 0.8548
Epoch 1/10, train loss: 2.3069, train metric: 0.1144, valid metric: 0.1082
Epoch 2/10, train loss: 2.2993, train metric: 0.1231, valid metric: 0.1294
Epoch 3/10, train loss: 2.2914, train metric: 0.1606, valid metric: 0.1710
Epoch 4/10, train loss: 2.2836, train metric: 0.1839, valid metric: 0.1840
Epoch 5/10, train loss: 2.2762, train metric: 0.1891, valid metric: 0.1856
Epoch 6/10, train loss: 2.2692, train metric: 0.1910, valid metric: 0.1898
Epoch 7/10, train loss: 2.2623, train metric: 0.1933, valid metric: 0.1932
Epoch 8/10, train loss: 2.2554, train metric: 0.2000, valid metric: 0.2022
Epoch 9/10, train loss: 2.2485, train metric: 0.2122, valid metric: 0.2160</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:53:35,767] Trial 2 finished with value: 0.23340000212192535 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.8547999858856201.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 10/10, train loss: 2.2414, train metric: 0.2299, valid metric: 0.2334
Epoch 1/10, train loss: 2.3035, train metric: 0.1373, valid metric: 0.1526
Epoch 2/10, train loss: 2.3005, train metric: 0.1569, valid metric: 0.1724
Epoch 3/10, train loss: 2.2975, train metric: 0.1755, valid metric: 0.1896
Epoch 4/10, train loss: 2.2945, train metric: 0.1941, valid metric: 0.2132
Epoch 5/10, train loss: 2.2914, train metric: 0.2105, valid metric: 0.2288
Epoch 6/10, train loss: 2.2884, train metric: 0.2261, valid metric: 0.2418
Epoch 7/10, train loss: 2.2853, train metric: 0.2419, valid metric: 0.2580
Epoch 8/10, train loss: 2.2823, train metric: 0.2581, valid metric: 0.2742
Epoch 9/10, train loss: 2.2792, train metric: 0.2736, valid metric: 0.2918</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:56:05,015] Trial 3 finished with value: 0.30959999561309814 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.8547999858856201.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 10/10, train loss: 2.2761, train metric: 0.2897, valid metric: 0.3096
Epoch 1/10, train loss: 1.8379, train metric: 0.4869, valid metric: 0.6208
Epoch 2/10, train loss: 0.9751, train metric: 0.6666, valid metric: 0.6978
Epoch 3/10, train loss: 0.7608, train metric: 0.7253, valid metric: 0.7416
Epoch 4/10, train loss: 0.6704, train metric: 0.7639, valid metric: 0.7720
Epoch 5/10, train loss: 0.6108, train metric: 0.7913, valid metric: 0.7906
Epoch 6/10, train loss: 0.5687, train metric: 0.8053, valid metric: 0.8050
Epoch 7/10, train loss: 0.5386, train metric: 0.8164, valid metric: 0.8082
Epoch 8/10, train loss: 0.5158, train metric: 0.8243, valid metric: 0.8214
Epoch 9/10, train loss: 0.4988, train metric: 0.8279, valid metric: 0.8220</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:58:32,788] Trial 4 finished with value: 0.8220000267028809 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.8547999858856201.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 10/10, train loss: 0.4842, train metric: 0.8330, valid metric: 0.8092</code></pre>
</div>
</div>
<p>By default, Optuna uses the <em>Tree-structured Parzen Estimator</em> (TPE) algorithm to optimize the hyperparameters: this is a sequential model-based optimization algorithm, meaning it learns from past results to better select promising hyperparameters. In other words, Optuna starts with random hyperparameter values, but it progressively focuses its search on the most promising regions of the hyperparameter space. This allows Optuna to find much better hyperparameters than random search in the same amount of time.</p>
<p><strong>Tip</strong>: You can add more hyperparameters to the search space, such as the batch size, the type of optimizer, the number of hidden layers, or the type of activation function, but remember that the search space will grow exponentially as you add more hyperparameters, so make sure it’s worth the extra search time and compute.</p>
<p>Once Optuna is done, you can look at the best hyperparameters it found, as well as the corresponding validation accuracy:</p>
<div id="385c03ae" class="cell" data-outputid="b117a8f7-6fca-43cf-9d09-c1bc547fb33c" data-execution_count="92">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>study.best_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>{'learning_rate': 0.008471801418819975, 'n_hidden': 188}</code></pre>
</div>
</div>
<div id="131fa51a" class="cell" data-outputid="58bf3279-8577-47b7-a701-ce07c5c4c19a" data-execution_count="93">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>study.best_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>0.8547999858856201</code></pre>
</div>
</div>
<p>This is slightly better than the performance we got earlier. If you increase <code>n_trials</code> up to 50 or more, you will get much better results, but of course it will take hours to run. You can also just run <code>optimize()</code> repeatedly and stop once you are happy with the performance.</p>
<p><strong>Tip</strong>: Optuna can also run trials in parallel across multiple machines, which can offer a near linear speed boost. For this, you will need to set up a SQL database (e.g., SQLite or PostgreSQL), and set the <code>storage</code> parameter of the <code>create_study()</code> function to point to that database. You also need to set the study’s name via the <code>study_name</code> parameter, and set <code>load_if_exists=True</code>. After that, you can copy your hyperparameter tuning script to multiple machines, and run it on each one (if you are using random seeds, make sure they are different on each machine). The scripts will work in parallel, reading and writing the trial results to the database. This has the additional benefit of keeping a full log of all your experiment results.</p>
<p>You may have noticed that we assumed that the <code>objective()</code> function had direct access to the training set and validation, presumably via global variables. In general, it’s much cleaner to pass them as extra arguments to the <code>objective()</code> function, for example, like this:</p>
<div id="351896d3" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial, train_loader, valid_loader):</span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the rest of the function remains the same as above</span></span>
<span id="cb167-3"><a href="#cb167-3" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> trial.suggest_float(<span class="st">"learning_rate"</span>, <span class="fl">1e-5</span>, <span class="fl">1e-1</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb167-4"><a href="#cb167-4" aria-hidden="true" tabindex="-1"></a>    n_hidden <span class="op">=</span> trial.suggest_int(<span class="st">"n_hidden"</span>, <span class="dv">20</span>, <span class="dv">300</span>)</span>
<span id="cb167-5"><a href="#cb167-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ImageClassifier(n_inputs<span class="op">=</span><span class="dv">1</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, n_hidden1<span class="op">=</span>n_hidden,</span>
<span id="cb167-6"><a href="#cb167-6" aria-hidden="true" tabindex="-1"></a>                            n_hidden2<span class="op">=</span>n_hidden, n_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span>
<span id="cb167-7"><a href="#cb167-7" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb167-8"><a href="#cb167-8" aria-hidden="true" tabindex="-1"></a>    xentropy <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb167-9"><a href="#cb167-9" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> torchmetrics.Accuracy(task<span class="op">=</span><span class="st">"multiclass"</span>, num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb167-10"><a href="#cb167-10" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> accuracy.to(device)</span>
<span id="cb167-11"><a href="#cb167-11" aria-hidden="true" tabindex="-1"></a>    best_validation_accuracy <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb167-12"><a href="#cb167-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train for multiple epochs, reporting intermediate results</span></span>
<span id="cb167-13"><a href="#cb167-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb167-14"><a href="#cb167-14" aria-hidden="true" tabindex="-1"></a>        history <span class="op">=</span> train2(model, optimizer, xentropy, accuracy, train_loader,</span>
<span id="cb167-15"><a href="#cb167-15" aria-hidden="true" tabindex="-1"></a>                         valid_loader, n_epochs<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb167-16"><a href="#cb167-16" aria-hidden="true" tabindex="-1"></a>        validation_accuracy <span class="op">=</span> <span class="bu">max</span>(history[<span class="st">"valid_metrics"</span>])</span>
<span id="cb167-17"><a href="#cb167-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> validation_accuracy <span class="op">&gt;</span> best_validation_accuracy:</span>
<span id="cb167-18"><a href="#cb167-18" aria-hidden="true" tabindex="-1"></a>            best_validation_accuracy <span class="op">=</span> validation_accuracy</span>
<span id="cb167-19"><a href="#cb167-19" aria-hidden="true" tabindex="-1"></a>        trial.report(validation_accuracy, epoch)</span>
<span id="cb167-20"><a href="#cb167-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> trial.should_prune():</span>
<span id="cb167-21"><a href="#cb167-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> optuna.TrialPruned()</span>
<span id="cb167-22"><a href="#cb167-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_validation_accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f3eca864" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>objective_with_data <span class="op">=</span> <span class="kw">lambda</span> trial: objective(</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>    trial, train_loader<span class="op">=</span>train_loader, valid_loader<span class="op">=</span>valid_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To set the extra arguments (the dataset loaders in this case), we just create a lambda function when needed and pass it to the <code>optimize()</code> method. Alternatively, you can use the <code>functools.partial()</code> function which creates a thin wrapper function around the given callable to provide default values for any number of arguments:</p>
<div id="f9b5c146" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a>objective_with_data <span class="op">=</span> partial(objective, train_loader<span class="op">=</span>train_loader,</span>
<span id="cb169-4"><a href="#cb169-4" aria-hidden="true" tabindex="-1"></a>                              valid_loader<span class="op">=</span>valid_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c298acf2" class="cell" data-outputid="07c367c8-b96a-4fe3-ac9c-4b68b3e2f4a2" data-execution_count="97">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>objective_with_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>functools.partial(&lt;function objective at 0x79aa3120be20&gt;, train_loader=&lt;torch.utils.data.dataloader.DataLoader object at 0x79abae871400&gt;, valid_loader=&lt;torch.utils.data.dataloader.DataLoader object at 0x79aa42d31dc0&gt;)</code></pre>
</div>
</div>
<p><strong>Tip</strong>: It’s often possible to quickly tell that a trial is absolutely terrible: for example, when the loss shoots up during the first epoch, or when the model barely improves during the first few epochs. In such a case, it’s a good idea to interrupt training early to avoid wasting time and compute. You can simply return the model’s current validation accuracy and hope that Optuna will learn to avoid this region of hyperparameter space. Alternatively, you can interrupt training by raising the <code>optuna.TrialPruned</code> exception: this tells Optuna to ignore this trial altogether. In many cases, this leads to a more efficient search because it avoids polluting Optuna’s search algorithm with many noisy model evaluations.</p>
<p>Optuna comes with several <code>Pruner</code> classes that can detect and prune bad trials. For example, the <code>MedianPruner</code> will prune trials whose performance is below the median performance, at regular intervals during training. It starts pruning after a given number of trials have completed, controlled by <code>n_startup_trials</code> (5 by default). For each trial after that, it lets training start for a few epochs, controlled by <code>n_warmup_steps</code> (0 by default); then every few epochs (controlled by <code>interval_steps</code>), it ensures that the model’s performance is better than the median performance at the same epoch in past trials. To use this pruner, create an instance and pass it to the <code>create_study()</code> method:</p>
<div id="2df91f92" class="cell" data-outputid="ed32d6c7-27af-479a-e18b-49f5e15d59e2" data-execution_count="98">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> optuna.samplers.TPESampler(seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>pruner <span class="op">=</span> optuna.pruners.MedianPruner()</span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">"maximize"</span>, sampler<span class="op">=</span>sampler,</span>
<span id="cb172-5"><a href="#cb172-5" aria-hidden="true" tabindex="-1"></a>                            pruner<span class="op">=</span>pruner)</span>
<span id="cb172-6"><a href="#cb172-6" aria-hidden="true" tabindex="-1"></a>study.optimize(objective_with_data, n_trials<span class="op">=</span><span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 06:58:32,834] A new study created in memory with name: no-name-b1f1f2ff-4366-4797-844a-d40ce0c52f7b</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860
Epoch 1/1, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500
Epoch 1/1, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554
Epoch 1/1, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562
Epoch 1/1, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026
Epoch 1/1, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228
Epoch 1/1, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326
Epoch 1/1, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372
Epoch 1/1, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424
Epoch 1/1, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436
Epoch 1/1, train loss: 1.0162, train metric: 0.6611, valid metric: 0.6530
Epoch 1/1, train loss: 0.9665, train metric: 0.6689, valid metric: 0.6620
Epoch 1/1, train loss: 0.9258, train metric: 0.6761, valid metric: 0.6700
Epoch 1/1, train loss: 0.8919, train metric: 0.6835, valid metric: 0.6782
Epoch 1/1, train loss: 0.8629, train metric: 0.6897, valid metric: 0.6848
Epoch 1/1, train loss: 0.8381, train metric: 0.6954, valid metric: 0.6876
Epoch 1/1, train loss: 0.8166, train metric: 0.7009, valid metric: 0.6932
Epoch 1/1, train loss: 0.7974, train metric: 0.7073, valid metric: 0.6964
Epoch 1/1, train loss: 0.7802, train metric: 0.7119, valid metric: 0.7090</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:03:30,077] Trial 0 finished with value: 0.7089999914169312 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.7089999914169312.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.7647, train metric: 0.7196, valid metric: 0.7082
Epoch 1/1, train loss: 1.1485, train metric: 0.6157, valid metric: 0.7332
Epoch 1/1, train loss: 0.6133, train metric: 0.7864, valid metric: 0.8082
Epoch 1/1, train loss: 0.5200, train metric: 0.8179, valid metric: 0.8136
Epoch 1/1, train loss: 0.4783, train metric: 0.8311, valid metric: 0.8232
Epoch 1/1, train loss: 0.4533, train metric: 0.8402, valid metric: 0.8020
Epoch 1/1, train loss: 0.4357, train metric: 0.8465, valid metric: 0.8446
Epoch 1/1, train loss: 0.4211, train metric: 0.8510, valid metric: 0.8276
Epoch 1/1, train loss: 0.4083, train metric: 0.8562, valid metric: 0.8398
Epoch 1/1, train loss: 0.3981, train metric: 0.8606, valid metric: 0.8532
Epoch 1/1, train loss: 0.3881, train metric: 0.8640, valid metric: 0.8582
Epoch 1/1, train loss: 0.3782, train metric: 0.8663, valid metric: 0.8532
Epoch 1/1, train loss: 0.3699, train metric: 0.8693, valid metric: 0.8566
Epoch 1/1, train loss: 0.3631, train metric: 0.8712, valid metric: 0.8574
Epoch 1/1, train loss: 0.3554, train metric: 0.8745, valid metric: 0.8494
Epoch 1/1, train loss: 0.3477, train metric: 0.8764, valid metric: 0.8672
Epoch 1/1, train loss: 0.3420, train metric: 0.8786, valid metric: 0.8520
Epoch 1/1, train loss: 0.3366, train metric: 0.8807, valid metric: 0.8680
Epoch 1/1, train loss: 0.3299, train metric: 0.8820, valid metric: 0.8666
Epoch 1/1, train loss: 0.3246, train metric: 0.8841, valid metric: 0.8672</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:08:24,936] Trial 1 finished with value: 0.8679999709129333 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.8679999709129333.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.3191, train metric: 0.8862, valid metric: 0.8638
Epoch 1/1, train loss: 2.2998, train metric: 0.1078, valid metric: 0.1152
Epoch 1/1, train loss: 2.2923, train metric: 0.1305, valid metric: 0.1432
Epoch 1/1, train loss: 2.2856, train metric: 0.1605, valid metric: 0.1704
Epoch 1/1, train loss: 2.2797, train metric: 0.1872, valid metric: 0.1912
Epoch 1/1, train loss: 2.2744, train metric: 0.2091, valid metric: 0.2114
Epoch 1/1, train loss: 2.2693, train metric: 0.2230, valid metric: 0.2216
Epoch 1/1, train loss: 2.2643, train metric: 0.2332, valid metric: 0.2320
Epoch 1/1, train loss: 2.2591, train metric: 0.2408, valid metric: 0.2380
Epoch 1/1, train loss: 2.2538, train metric: 0.2456, valid metric: 0.2424
Epoch 1/1, train loss: 2.2481, train metric: 0.2493, valid metric: 0.2456
Epoch 1/1, train loss: 2.2422, train metric: 0.2511, valid metric: 0.2464
Epoch 1/1, train loss: 2.2360, train metric: 0.2534, valid metric: 0.2476
Epoch 1/1, train loss: 2.2296, train metric: 0.2538, valid metric: 0.2478
Epoch 1/1, train loss: 2.2229, train metric: 0.2535, valid metric: 0.2482
Epoch 1/1, train loss: 2.2160, train metric: 0.2544, valid metric: 0.2492
Epoch 1/1, train loss: 2.2086, train metric: 0.2549, valid metric: 0.2508
Epoch 1/1, train loss: 2.2009, train metric: 0.2561, valid metric: 0.2522
Epoch 1/1, train loss: 2.1928, train metric: 0.2572, valid metric: 0.2520
Epoch 1/1, train loss: 2.1842, train metric: 0.2582, valid metric: 0.2526</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:13:19,298] Trial 2 finished with value: 0.25380000472068787 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.8679999709129333.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.1751, train metric: 0.2610, valid metric: 0.2538
Epoch 1/1, train loss: 2.3015, train metric: 0.0997, valid metric: 0.1028
Epoch 1/1, train loss: 2.2984, train metric: 0.1009, valid metric: 0.1050
Epoch 1/1, train loss: 2.2953, train metric: 0.1051, valid metric: 0.1124
Epoch 1/1, train loss: 2.2923, train metric: 0.1160, valid metric: 0.1270
Epoch 1/1, train loss: 2.2894, train metric: 0.1347, valid metric: 0.1496
Epoch 1/1, train loss: 2.2865, train metric: 0.1548, valid metric: 0.1652
Epoch 1/1, train loss: 2.2837, train metric: 0.1699, valid metric: 0.1800
Epoch 1/1, train loss: 2.2808, train metric: 0.1800, valid metric: 0.1872
Epoch 1/1, train loss: 2.2780, train metric: 0.1855, valid metric: 0.1916
Epoch 1/1, train loss: 2.2752, train metric: 0.1893, valid metric: 0.1960
Epoch 1/1, train loss: 2.2725, train metric: 0.1950, valid metric: 0.2008
Epoch 1/1, train loss: 2.2697, train metric: 0.2000, valid metric: 0.2026
Epoch 1/1, train loss: 2.2669, train metric: 0.2058, valid metric: 0.2046
Epoch 1/1, train loss: 2.2641, train metric: 0.2124, valid metric: 0.2116
Epoch 1/1, train loss: 2.2613, train metric: 0.2177, valid metric: 0.2166
Epoch 1/1, train loss: 2.2585, train metric: 0.2238, valid metric: 0.2224
Epoch 1/1, train loss: 2.2556, train metric: 0.2289, valid metric: 0.2264
Epoch 1/1, train loss: 2.2528, train metric: 0.2339, valid metric: 0.2314
Epoch 1/1, train loss: 2.2498, train metric: 0.2383, valid metric: 0.2342</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:18:13,237] Trial 3 finished with value: 0.23960000276565552 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.8679999709129333.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.2469, train metric: 0.2429, valid metric: 0.2396
Epoch 1/1, train loss: 1.8945, train metric: 0.4923, valid metric: 0.6290
Epoch 1/1, train loss: 1.0016, train metric: 0.6582, valid metric: 0.6772
Epoch 1/1, train loss: 0.7747, train metric: 0.7115, valid metric: 0.7248
Epoch 1/1, train loss: 0.6864, train metric: 0.7551, valid metric: 0.7596
Epoch 1/1, train loss: 0.6268, train metric: 0.7833, valid metric: 0.7806
Epoch 1/1, train loss: 0.5830, train metric: 0.8000, valid metric: 0.7864
Epoch 1/1, train loss: 0.5500, train metric: 0.8113, valid metric: 0.8064
Epoch 1/1, train loss: 0.5252, train metric: 0.8184, valid metric: 0.8130
Epoch 1/1, train loss: 0.5061, train metric: 0.8238, valid metric: 0.8204
Epoch 1/1, train loss: 0.4908, train metric: 0.8290, valid metric: 0.8206
Epoch 1/1, train loss: 0.4777, train metric: 0.8338, valid metric: 0.8150
Epoch 1/1, train loss: 0.4681, train metric: 0.8375, valid metric: 0.8304
Epoch 1/1, train loss: 0.4591, train metric: 0.8403, valid metric: 0.8320
Epoch 1/1, train loss: 0.4516, train metric: 0.8429, valid metric: 0.8314
Epoch 1/1, train loss: 0.4447, train metric: 0.8460, valid metric: 0.8346
Epoch 1/1, train loss: 0.4380, train metric: 0.8474, valid metric: 0.8360
Epoch 1/1, train loss: 0.4321, train metric: 0.8496, valid metric: 0.8378
Epoch 1/1, train loss: 0.4272, train metric: 0.8512, valid metric: 0.8364
Epoch 1/1, train loss: 0.4223, train metric: 0.8528, valid metric: 0.8406</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:23:13,606] Trial 4 finished with value: 0.8429999947547913 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.8679999709129333.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.4173, train metric: 0.8556, valid metric: 0.8430</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:23:28,194] Trial 5 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.3017, train metric: 0.1007, valid metric: 0.1056
Epoch 1/1, train loss: 0.8584, train metric: 0.7026, valid metric: 0.7982
Epoch 1/1, train loss: 0.5069, train metric: 0.8211, valid metric: 0.8228
Epoch 1/1, train loss: 0.4499, train metric: 0.8404, valid metric: 0.8340
Epoch 1/1, train loss: 0.4183, train metric: 0.8517, valid metric: 0.8512
Epoch 1/1, train loss: 0.3936, train metric: 0.8579, valid metric: 0.8478
Epoch 1/1, train loss: 0.3755, train metric: 0.8661, valid metric: 0.8520
Epoch 1/1, train loss: 0.3602, train metric: 0.8699, valid metric: 0.8640
Epoch 1/1, train loss: 0.3477, train metric: 0.8746, valid metric: 0.8666
Epoch 1/1, train loss: 0.3359, train metric: 0.8784, valid metric: 0.8712
Epoch 1/1, train loss: 0.3264, train metric: 0.8823, valid metric: 0.8712
Epoch 1/1, train loss: 0.3180, train metric: 0.8846, valid metric: 0.8698
Epoch 1/1, train loss: 0.3097, train metric: 0.8864, valid metric: 0.8784
Epoch 1/1, train loss: 0.3021, train metric: 0.8903, valid metric: 0.8666
Epoch 1/1, train loss: 0.2951, train metric: 0.8917, valid metric: 0.8710
Epoch 1/1, train loss: 0.2887, train metric: 0.8942, valid metric: 0.8698
Epoch 1/1, train loss: 0.2824, train metric: 0.8964, valid metric: 0.8716
Epoch 1/1, train loss: 0.2762, train metric: 0.8993, valid metric: 0.8806
Epoch 1/1, train loss: 0.2699, train metric: 0.9011, valid metric: 0.8802
Epoch 1/1, train loss: 0.2646, train metric: 0.9036, valid metric: 0.8776</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:28:19,068] Trial 6 finished with value: 0.8853999972343445 and parameters: {'learning_rate': 0.021368329072358756, 'n_hidden': 79}. Best is trial 6 with value: 0.8853999972343445.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2600, train metric: 0.9043, valid metric: 0.8854</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:28:33,746] Trial 7 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.2926, train metric: 0.1081, valid metric: 0.1064</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:28:48,203] Trial 8 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.2836, train metric: 0.1225, valid metric: 0.1526</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:29:02,820] Trial 9 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 2.2631, train metric: 0.2483, valid metric: 0.3554
Epoch 1/1, train loss: 0.6987, train metric: 0.7437, valid metric: 0.8334
Epoch 1/1, train loss: 0.4543, train metric: 0.8360, valid metric: 0.8288
Epoch 1/1, train loss: 0.4144, train metric: 0.8490, valid metric: 0.8488
Epoch 1/1, train loss: 0.3903, train metric: 0.8575, valid metric: 0.8354
Epoch 1/1, train loss: 0.3719, train metric: 0.8637, valid metric: 0.8454
Epoch 1/1, train loss: 0.3600, train metric: 0.8676, valid metric: 0.8538
Epoch 1/1, train loss: 0.3476, train metric: 0.8716, valid metric: 0.8554
Epoch 1/1, train loss: 0.3408, train metric: 0.8744, valid metric: 0.8570
Epoch 1/1, train loss: 0.3327, train metric: 0.8781, valid metric: 0.8526
Epoch 1/1, train loss: 0.3281, train metric: 0.8784, valid metric: 0.8620
Epoch 1/1, train loss: 0.3220, train metric: 0.8824, valid metric: 0.8650
Epoch 1/1, train loss: 0.3178, train metric: 0.8827, valid metric: 0.8680
Epoch 1/1, train loss: 0.3126, train metric: 0.8851, valid metric: 0.8588
Epoch 1/1, train loss: 0.3094, train metric: 0.8862, valid metric: 0.8560
Epoch 1/1, train loss: 0.3053, train metric: 0.8866, valid metric: 0.8676
Epoch 1/1, train loss: 0.3016, train metric: 0.8881, valid metric: 0.8596
Epoch 1/1, train loss: 0.2989, train metric: 0.8902, valid metric: 0.8716
Epoch 1/1, train loss: 0.2956, train metric: 0.8909, valid metric: 0.8586
Epoch 1/1, train loss: 0.2915, train metric: 0.8909, valid metric: 0.8744</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:33:58,557] Trial 10 finished with value: 0.8744000196456909 and parameters: {'learning_rate': 0.08165528450509137, 'n_hidden': 21}. Best is trial 6 with value: 0.8853999972343445.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2908, train metric: 0.8915, valid metric: 0.8604
Epoch 1/1, train loss: 0.6527, train metric: 0.7611, valid metric: 0.8132
Epoch 1/1, train loss: 0.4509, train metric: 0.8355, valid metric: 0.8452
Epoch 1/1, train loss: 0.4139, train metric: 0.8495, valid metric: 0.8462
Epoch 1/1, train loss: 0.3909, train metric: 0.8578, valid metric: 0.8522
Epoch 1/1, train loss: 0.3755, train metric: 0.8626, valid metric: 0.8498
Epoch 1/1, train loss: 0.3641, train metric: 0.8658, valid metric: 0.8566
Epoch 1/1, train loss: 0.3536, train metric: 0.8695, valid metric: 0.8534
Epoch 1/1, train loss: 0.3476, train metric: 0.8734, valid metric: 0.8600
Epoch 1/1, train loss: 0.3391, train metric: 0.8772, valid metric: 0.8556
Epoch 1/1, train loss: 0.3309, train metric: 0.8779, valid metric: 0.8600
Epoch 1/1, train loss: 0.3271, train metric: 0.8809, valid metric: 0.8628
Epoch 1/1, train loss: 0.3212, train metric: 0.8814, valid metric: 0.8650
Epoch 1/1, train loss: 0.3187, train metric: 0.8829, valid metric: 0.8686
Epoch 1/1, train loss: 0.3132, train metric: 0.8844, valid metric: 0.8612
Epoch 1/1, train loss: 0.3095, train metric: 0.8848, valid metric: 0.8634
Epoch 1/1, train loss: 0.3076, train metric: 0.8869, valid metric: 0.8628
Epoch 1/1, train loss: 0.3024, train metric: 0.8875, valid metric: 0.8438
Epoch 1/1, train loss: 0.2976, train metric: 0.8899, valid metric: 0.8542
Epoch 1/1, train loss: 0.2958, train metric: 0.8909, valid metric: 0.8580</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:38:49,350] Trial 11 finished with value: 0.8686000108718872 and parameters: {'learning_rate': 0.07553503645583189, 'n_hidden': 21}. Best is trial 6 with value: 0.8853999972343445.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2937, train metric: 0.8901, valid metric: 0.8550
Epoch 1/1, train loss: 0.6195, train metric: 0.7764, valid metric: 0.8170
Epoch 1/1, train loss: 0.4179, train metric: 0.8472, valid metric: 0.8488
Epoch 1/1, train loss: 0.3729, train metric: 0.8637, valid metric: 0.8500
Epoch 1/1, train loss: 0.3477, train metric: 0.8713, valid metric: 0.8666
Epoch 1/1, train loss: 0.3280, train metric: 0.8791, valid metric: 0.8670
Epoch 1/1, train loss: 0.3120, train metric: 0.8842, valid metric: 0.8716
Epoch 1/1, train loss: 0.2989, train metric: 0.8886, valid metric: 0.8730
Epoch 1/1, train loss: 0.2866, train metric: 0.8923, valid metric: 0.8780
Epoch 1/1, train loss: 0.2771, train metric: 0.8978, valid metric: 0.8544
Epoch 1/1, train loss: 0.2690, train metric: 0.8984, valid metric: 0.8774
Epoch 1/1, train loss: 0.2588, train metric: 0.9028, valid metric: 0.8776
Epoch 1/1, train loss: 0.2506, train metric: 0.9062, valid metric: 0.8808
Epoch 1/1, train loss: 0.2432, train metric: 0.9081, valid metric: 0.8842
Epoch 1/1, train loss: 0.2368, train metric: 0.9099, valid metric: 0.8822
Epoch 1/1, train loss: 0.2318, train metric: 0.9125, valid metric: 0.8824
Epoch 1/1, train loss: 0.2254, train metric: 0.9149, valid metric: 0.8840
Epoch 1/1, train loss: 0.2192, train metric: 0.9173, valid metric: 0.8868
Epoch 1/1, train loss: 0.2142, train metric: 0.9193, valid metric: 0.8862
Epoch 1/1, train loss: 0.2098, train metric: 0.9213, valid metric: 0.8848</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:43:38,994] Trial 12 finished with value: 0.8867999911308289 and parameters: {'learning_rate': 0.08525846269447772, 'n_hidden': 116}. Best is trial 12 with value: 0.8867999911308289.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2030, train metric: 0.9223, valid metric: 0.8744
Epoch 1/1, train loss: 0.8659, train metric: 0.7036, valid metric: 0.7850
Epoch 1/1, train loss: 0.5120, train metric: 0.8185, valid metric: 0.8188
Epoch 1/1, train loss: 0.4574, train metric: 0.8378, valid metric: 0.8286
Epoch 1/1, train loss: 0.4263, train metric: 0.8487, valid metric: 0.8460
Epoch 1/1, train loss: 0.4035, train metric: 0.8569, valid metric: 0.8448
Epoch 1/1, train loss: 0.3874, train metric: 0.8618, valid metric: 0.8476
Epoch 1/1, train loss: 0.3711, train metric: 0.8666, valid metric: 0.8340
Epoch 1/1, train loss: 0.3580, train metric: 0.8712, valid metric: 0.8580
Epoch 1/1, train loss: 0.3456, train metric: 0.8760, valid metric: 0.8660
Epoch 1/1, train loss: 0.3345, train metric: 0.8791, valid metric: 0.8686
Epoch 1/1, train loss: 0.3258, train metric: 0.8815, valid metric: 0.8662
Epoch 1/1, train loss: 0.3169, train metric: 0.8858, valid metric: 0.8750
Epoch 1/1, train loss: 0.3089, train metric: 0.8879, valid metric: 0.8746
Epoch 1/1, train loss: 0.3016, train metric: 0.8903, valid metric: 0.8766
Epoch 1/1, train loss: 0.2944, train metric: 0.8931, valid metric: 0.8740
Epoch 1/1, train loss: 0.2885, train metric: 0.8951, valid metric: 0.8748
Epoch 1/1, train loss: 0.2822, train metric: 0.8977, valid metric: 0.8722
Epoch 1/1, train loss: 0.2770, train metric: 0.8997, valid metric: 0.8698
Epoch 1/1, train loss: 0.2729, train metric: 0.9007, valid metric: 0.8670</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:48:22,958] Trial 13 finished with value: 0.8784000277519226 and parameters: {'learning_rate': 0.01891149541864801, 'n_hidden': 116}. Best is trial 12 with value: 0.8867999911308289.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2671, train metric: 0.9020, valid metric: 0.8784
Epoch 1/1, train loss: 0.9440, train metric: 0.6748, valid metric: 0.7730
Epoch 1/1, train loss: 0.5292, train metric: 0.8132, valid metric: 0.8262
Epoch 1/1, train loss: 0.4689, train metric: 0.8346, valid metric: 0.8306
Epoch 1/1, train loss: 0.4349, train metric: 0.8445, valid metric: 0.8290
Epoch 1/1, train loss: 0.4107, train metric: 0.8556, valid metric: 0.8436</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:49:49,738] Trial 14 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.3919, train metric: 0.8613, valid metric: 0.8300</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:50:03,880] Trial 15 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 1.8496, train metric: 0.4092, valid metric: 0.6042
Epoch 1/1, train loss: 0.7456, train metric: 0.7386, valid metric: 0.7672
Epoch 1/1, train loss: 0.4683, train metric: 0.8341, valid metric: 0.8424
Epoch 1/1, train loss: 0.4143, train metric: 0.8511, valid metric: 0.8464
Epoch 1/1, train loss: 0.3811, train metric: 0.8621, valid metric: 0.8568
Epoch 1/1, train loss: 0.3579, train metric: 0.8696, valid metric: 0.8682
Epoch 1/1, train loss: 0.3400, train metric: 0.8758, valid metric: 0.8690
Epoch 1/1, train loss: 0.3261, train metric: 0.8804, valid metric: 0.8708
Epoch 1/1, train loss: 0.3149, train metric: 0.8837, valid metric: 0.8794
Epoch 1/1, train loss: 0.3020, train metric: 0.8895, valid metric: 0.8714
Epoch 1/1, train loss: 0.2935, train metric: 0.8930, valid metric: 0.8400
Epoch 1/1, train loss: 0.2845, train metric: 0.8949, valid metric: 0.8720
Epoch 1/1, train loss: 0.2761, train metric: 0.8982, valid metric: 0.8792
Epoch 1/1, train loss: 0.2684, train metric: 0.9003, valid metric: 0.8848
Epoch 1/1, train loss: 0.2615, train metric: 0.9045, valid metric: 0.8772
Epoch 1/1, train loss: 0.2560, train metric: 0.9049, valid metric: 0.8820
Epoch 1/1, train loss: 0.2497, train metric: 0.9071, valid metric: 0.8832
Epoch 1/1, train loss: 0.2434, train metric: 0.9097, valid metric: 0.8848
Epoch 1/1, train loss: 0.2380, train metric: 0.9126, valid metric: 0.8832
Epoch 1/1, train loss: 0.2331, train metric: 0.9145, valid metric: 0.8806</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:54:52,322] Trial 16 finished with value: 0.8848000168800354 and parameters: {'learning_rate': 0.032666299131732864, 'n_hidden': 142}. Best is trial 12 with value: 0.8867999911308289.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2271, train metric: 0.9154, valid metric: 0.8800</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:55:06,937] Trial 17 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 1.5604, train metric: 0.5038, valid metric: 0.6536
Epoch 1/1, train loss: 0.6189, train metric: 0.7751, valid metric: 0.8314
Epoch 1/1, train loss: 0.4237, train metric: 0.8447, valid metric: 0.8492
Epoch 1/1, train loss: 0.3814, train metric: 0.8605, valid metric: 0.8582
Epoch 1/1, train loss: 0.3567, train metric: 0.8681, valid metric: 0.8622
Epoch 1/1, train loss: 0.3375, train metric: 0.8744, valid metric: 0.8674
Epoch 1/1, train loss: 0.3246, train metric: 0.8788, valid metric: 0.8480
Epoch 1/1, train loss: 0.3123, train metric: 0.8849, valid metric: 0.8644
Epoch 1/1, train loss: 0.3012, train metric: 0.8871, valid metric: 0.8734
Epoch 1/1, train loss: 0.2915, train metric: 0.8916, valid metric: 0.8760
Epoch 1/1, train loss: 0.2858, train metric: 0.8931, valid metric: 0.8758
Epoch 1/1, train loss: 0.2778, train metric: 0.8955, valid metric: 0.8804
Epoch 1/1, train loss: 0.2715, train metric: 0.8972, valid metric: 0.8616
Epoch 1/1, train loss: 0.2642, train metric: 0.9011, valid metric: 0.8800
Epoch 1/1, train loss: 0.2598, train metric: 0.9009, valid metric: 0.8782
Epoch 1/1, train loss: 0.2561, train metric: 0.9033, valid metric: 0.8734
Epoch 1/1, train loss: 0.2494, train metric: 0.9058, valid metric: 0.8788
Epoch 1/1, train loss: 0.2474, train metric: 0.9069, valid metric: 0.8720
Epoch 1/1, train loss: 0.2411, train metric: 0.9089, valid metric: 0.8750
Epoch 1/1, train loss: 0.2375, train metric: 0.9103, valid metric: 0.8768</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 07:59:57,415] Trial 18 finished with value: 0.8830000162124634 and parameters: {'learning_rate': 0.0954812841907134, 'n_hidden': 50}. Best is trial 12 with value: 0.8867999911308289.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8830</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2025-12-01 08:00:12,000] Trial 19 pruned. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1, train loss: 0.7417, train metric: 0.7395, valid metric: 0.7640</code></pre>
</div>
</div>
<div id="ac50a06a" class="cell" data-outputid="1552e3eb-6957-47c8-9701-465d398d60d3" data-execution_count="99">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>study.best_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>0.8867999911308289</code></pre>
</div>
</div>
<div id="a4d8ed85" class="cell" data-outputid="858382fe-e22b-421c-ff9c-91db88874709" data-execution_count="100">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>study.best_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>{'learning_rate': 0.08525846269447772, 'n_hidden': 116}</code></pre>
</div>
</div>
<p>Notice we modified the <code>objective()</code> so it runs after each epoch.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb219-2"><a href="#cb219-2" aria-hidden="true" tabindex="-1"></a>    [...]  <span class="co"># train the model for one epoch</span></span>
<span id="cb219-3"><a href="#cb219-3" aria-hidden="true" tabindex="-1"></a>    validation_accuracy <span class="op">=</span> [...]  <span class="co"># evaluate the model's validation accuracy</span></span>
<span id="cb219-4"><a href="#cb219-4" aria-hidden="true" tabindex="-1"></a>    trial.report(validation_accuracy, epoch)</span>
<span id="cb219-5"><a href="#cb219-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> trial.should_prune():</span>
<span id="cb219-6"><a href="#cb219-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> optuna.TrialPruned()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>report()</code> method informs Optuna of the current validation accuracy and epoch, so it can determine whether the trial should be pruned. If <code>trial.should_prune()</code> returns <code>True</code>, we raise a <code>TrialPruned</code> exception.</p>
<p><strong>Tip</strong>: Optuna has many other features well worth exploring, such as visualization tools, persistence tools for trial results and other artifacts, a dashboard for human-in-the-loop optimization, and many other algorithms for hyperparameter search and trial pruning.</p>
<p>Once you are happy with the hyperparameters, you can train the model on the full training set (i.e., the training set plus the validation set), then evaluate it on the test set. Hopefully, it will perform great!</p>
</section>
<section id="saving-and-loading-pytorch-models" class="level3">
<h3 class="anchored" data-anchor-id="saving-and-loading-pytorch-models">3.3.11 Saving and Loading PyTorch Models</h3>
<p>The simplest way to save a PyTorch model is to use the <code>torch.save()</code> method, passing it the model and the filepath. The model object is serialized using Python’s <code>pickle</code> module (which can convert objects into a sequence of bytes), then the result is compressed (zip) and saved to disk. The convention is to use the <code>.pt</code> or <code>.pth</code> extension for PyTorch files:</p>
<div id="b75fd8cc" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>torch.save(model, <span class="st">"my_fashion_mnist.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Simple! Now you can load the model (e.g., in your production code) just as easily:</p>
<div id="5bc6b8b3" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> torch.load(<span class="st">"my_fashion_mnist.pt"</span>, weights_only<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Warning</strong>: If your model uses any custom functions or classes (e.g., <code>ImageClassifier</code>), then <code>torch.save()</code> only saves references to them, not the code itself. Therefore you must ensure that any custom code is loaded in the Python environment before calling <code>torch.load()</code>. Also make sure to use the same version of the code to avoid any mismatch issues.</p>
<p>Setting <code>weights_only=False</code> ensures that the whole model object is loaded rather than just the model parameters. Then you can use the loaded model for inference. Don’t forget to switch to evaluation mode first using the <code>eval()</code> method:</p>
<div id="94e8ae70" class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>loaded_model.<span class="bu">eval</span>()</span>
<span id="cb222-2"><a href="#cb222-2" aria-hidden="true" tabindex="-1"></a>y_pred_logits <span class="op">=</span> loaded_model(X_new)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is nice and easy, but unfortunately this approach has some very serious drawbacks:</p>
<ul>
<li><p>Firstly, pickle’s serialization format is notoriously insecure. While <code>torch.save()</code> doesn’t save custom code, the pickle format supports it, so a hacker could inject malicious code in a saved PyTorch model: this code would be run automatically by the <code>pickle</code> module when the model is loaded. So always make sure you fully trust the model’s source before you load it this way.</p></li>
<li><p>Second, pickle is somewhat brittle. It can vary depending on the Python version (e.g., there were big changes between Python 3.7 and 3.8), and it saves specific filepaths to locate code, which can break if the loading environment has a different folder structure.</p></li>
</ul>
<p>To avoid these issues, it is recommended to save and load the model weights only, rather than the full model object:</p>
<div id="eb1735dd" class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="st">"my_fashion_mnist_weights.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The state dictionary returned by the <code>state_dict()</code> method is just a Python <code>OrderedDict</code> containing an entry for each parameter returned by the <code>named_parameters()</code> method. It also contains buffers, if the model has any: a buffer is just a regular tensor that was registered with the model (or any of its submodules) using the <code>register_buffer()</code> method. Buffers hold extra data that needs to be stored along with the model, but that is not a model parameter.</p>
<p>To load these weights, we must first create a model with the exact same structure, then load the weights using <code>torch.load()</code> with <code>weights_only=True</code>, and finally call the model’s <code>load_state_dict()</code> method with the loaded weights:</p>
<div id="ea578f87" class="cell" data-outputid="17bc42b7-eeda-4cb4-fc0f-5bfeb48e84ef" data-execution_count="105">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>new_model <span class="op">=</span> ImageClassifier(n_inputs<span class="op">=</span><span class="dv">1</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, n_hidden1<span class="op">=</span><span class="dv">300</span>, n_hidden2<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb224-2"><a href="#cb224-2" aria-hidden="true" tabindex="-1"></a>                            n_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb224-3"><a href="#cb224-3" aria-hidden="true" tabindex="-1"></a>loaded_weights <span class="op">=</span> torch.load(<span class="st">"my_fashion_mnist_weights.pt"</span>, weights_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb224-4"><a href="#cb224-4" aria-hidden="true" tabindex="-1"></a>new_model.load_state_dict(loaded_weights)</span>
<span id="cb224-5"><a href="#cb224-5" aria-hidden="true" tabindex="-1"></a>new_model.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>ImageClassifier(
  (mlp): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=784, out_features=300, bias=True)
    (2): ReLU()
    (3): Linear(in_features=300, out_features=100, bias=True)
    (4): ReLU()
    (5): Linear(in_features=100, out_features=10, bias=True)
  )
)</code></pre>
</div>
</div>
<p>The saved model contains only data, and the <code>torch.load()</code> function makes sure of that, so this is safe, and also much less likely to break between Python versions or to cause any deployment issue. However, it only works if you are able to create the exact same model architecture before loading the state dictionary. For this, you need to know the number of layers, the number of neurons per layer, and so on. It’s a good idea to save this information along with the state dictionary:</p>
<div id="c1f8920e" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>model_data <span class="op">=</span> {</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"model_state_dict"</span>: model.state_dict(),</span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"model_hyperparameters"</span>: {</span>
<span id="cb226-4"><a href="#cb226-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"n_inputs"</span>: <span class="dv">1</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,</span>
<span id="cb226-5"><a href="#cb226-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"n_hidden1"</span>: <span class="dv">300</span>,</span>
<span id="cb226-6"><a href="#cb226-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"n_hidden2"</span>: <span class="dv">100</span>,</span>
<span id="cb226-7"><a href="#cb226-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"n_classes"</span>: <span class="dv">10</span>,</span>
<span id="cb226-8"><a href="#cb226-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb226-9"><a href="#cb226-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb226-10"><a href="#cb226-10" aria-hidden="true" tabindex="-1"></a>torch.save(model_data, <span class="st">"my_fashion_mnist_model.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can then load this dictionary, construct the model based on the saved hyperparameters, and load the state dictionary into this model:</p>
<div id="ce3be1e9" class="cell" data-outputid="3e80a67e-ef9d-4bd7-d784-2e0209e9ab16" data-execution_count="107">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>loaded_data <span class="op">=</span> torch.load(<span class="st">"my_fashion_mnist_model.pt"</span>, weights_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb227-2"><a href="#cb227-2" aria-hidden="true" tabindex="-1"></a>new_model <span class="op">=</span> ImageClassifier(<span class="op">**</span>loaded_data[<span class="st">"model_hyperparameters"</span>])</span>
<span id="cb227-3"><a href="#cb227-3" aria-hidden="true" tabindex="-1"></a>new_model.load_state_dict(loaded_data[<span class="st">"model_state_dict"</span>])</span>
<span id="cb227-4"><a href="#cb227-4" aria-hidden="true" tabindex="-1"></a>new_model.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>ImageClassifier(
  (mlp): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=784, out_features=300, bias=True)
    (2): ReLU()
    (3): Linear(in_features=300, out_features=100, bias=True)
    (4): ReLU()
    (5): Linear(in_features=100, out_features=10, bias=True)
  )
)</code></pre>
</div>
</div>
<p>If you want to be able to continue training where it left off, you will also need to save the optimizer’s state dictionary, its hyperparameters, and any other training information you may need, such as the current epoch and the loss history.</p>
<p><strong>Tip</strong>: There is yet another way to save and load your model: by first converting it to TorchScript. This also makes it possible to speed up your model’s inference.</p>
<section id="for-further-exploration" class="level4">
<h4 class="anchored" data-anchor-id="for-further-exploration"><strong>For Further Exploration</strong></h4>
<hr>
<p><strong>References:</strong></p>
<p>Disclaimer: Some of the material in this notebook is adapted from other sources. These references are provided for further reading and to acknowledge the original authors.</p>
<ul>
<li>Chapter 10 Hands-On Machine Learning with Scikit-Learn and PyTorch by Aurélien Géron, <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9798341607972/">1st edition</a></li>
</ul>
<hr>
<p><strong>Assignment 3 (final project)</strong>:</p>
<p>It’s time to show off your skills! Build, train, and evaluate a neural network model using PyTorch on a dataset of your choice. You can use any dataset available online or one from your previous assignments. Make sure to preprocess the data appropriately, define a suitable architecture, and implement training and evaluation loops. Remember to document your code and explain your choices. You ought to follow a Data Science workflow, check the suggested workflow in Introduction to Data Science Course or develop your own (recommended minimal steps include data exploration, preprocessing, model building, training, evaluation, and fine-tuning). Submit your code along with a brief report summarizing your approach and findings (the format is free). Remember that a good Data Science project is not just about getting high accuracy but also about understanding the data and the model’s behavior. Make sure to highlight any challenges you faced and how you overcame them. Pinpoint areas for future improvement or exploration. Use clear visualizations to support your analysis where appropriate. And remember to make communications clear and concise. If you need inspiration, you can use the following idea:</p>
<p>Build and train a classification MLP on the CoverType dataset:</p>
<ol type="1">
<li>Load the dataset using <code>sklearn.datasets.fetch_covtype()</code> and create a custom PyTorch <code>Dataset</code> for this data.</li>
<li>Create data loaders for training, validation, and testing.</li>
<li>Build a custom MLP module to tackle this classification task.</li>
<li>Train this model on the GPU, and try to reach 93% accuracy on the test set. For this, you will likely have to perform hyperparameter search to find the right number of layers and neurons per layer, a good learning rate and batch size, and so on. You can optionally use Optuna for this.</li>
</ol>
<p>Good luck!</p>


</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/emilianodesu\.github\.io\/SIAFI-2026-1\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>